{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Week 3: Bivariate Data Summaries**\n",
        "\n",
        "```\n",
        ".------------------------------------.\n",
        "|   __  ____  ______  _  ___ _____   |\n",
        "|  |  \\/  \\ \\/ / __ )/ |/ _ \\___  |  |\n",
        "|  | |\\/| |\\  /|  _ \\| | | | | / /   |\n",
        "|  | |  | |/  \\| |_) | | |_| |/ /    |\n",
        "|  |_|  |_/_/\\_\\____/|_|\\___//_/     |\n",
        "'------------------------------------'\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "ZtpJJ8BSHOaK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This week, we‚Äôll explore statistical summaries of bivariate data and demonstrate how to compute them using R. If you are not familiar with R programming, please take some time to review [Week 0](https://colab.research.google.com/github/edelweiss611428/MXB107-Notebooks/blob/main/notebooks/Week_0.ipynb) and [Week 1](https://colab.research.google.com/github/edelweiss611428/MXB107-Notebooks/blob/main/notebooks/Week_1.ipynb) content.\n",
        "\n",
        "**You may notice some content overlaps with previous workshops. Consider this an opportunity to revisit earlier ideas and discover their connections to the current topics.**"
      ],
      "metadata": {
        "id": "QWuoIciBrV25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pre-Configurating the Notebook**"
      ],
      "metadata": {
        "id": "SpK9XLxlHOcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Switching to the R Kernel on Colab**\n",
        "\n",
        "By default, Google Colab uses Python as its programming language. To use R instead, you‚Äôll need to manually switch the kernel by going to **Runtime > Change runtime type**, and selecting R as the kernel. This allows you to run R code in the Colab environment.\n",
        "\n",
        "However, our notebook is already configured to use R by default. Unless something goes wrong, you shouldn‚Äôt need to manually change runtime type."
      ],
      "metadata": {
        "id": "4yA6tfrakIOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importing Required Datasets and Packages**\n",
        "**Run the following lines of code**:"
      ],
      "metadata": {
        "id": "VLNikK3CYWIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Do not modify\n",
        "\n",
        "setwd(\"/content\")\n",
        "\n",
        "# Remove `MXB107-Notebooks` if exists,\n",
        "if (dir.exists(\"MXB107-Notebooks\")) {\n",
        "  system(\"rm -rf MXB107-Notebooks\")\n",
        "}\n",
        "\n",
        "# Fork the repository\n",
        "system(\"git clone https://github.com/edelweiss611428/MXB107-Notebooks.git\")\n",
        "\n",
        "# Change working directory to \"MXB107-Notebooks\"\n",
        "setwd(\"MXB107-Notebooks\")\n",
        "\n",
        "#\n",
        "invisible(source(\"R/preConfigurated.R\"))"
      ],
      "metadata": {
        "id": "tYGemispahiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do not modify the following**"
      ],
      "metadata": {
        "id": "o_XFVhdp1GrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (!require(\"testthat\")) install.packages(\"testthat\"); library(\"testthat\")\n",
        "\n",
        "test_that(\"Test if all packages have been loaded\", {\n",
        "\n",
        "  expect_true(all(c(\"ggplot2\", \"tidyr\", \"dplyr\", \"stringr\", \"magrittr\", \"knitr\") %in% loadedNamespaces()))\n",
        "\n",
        "})"
      ],
      "metadata": {
        "id": "6lru0NFK011G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Multivariate Data**\n",
        "\n",
        "Multivariate data arises when we collect more than one observations per experimental unit, for example surveys can ask individuals multiple questions, resulting in a multivariate data set.\n"
      ],
      "metadata": {
        "id": "ljByRcTl_QwK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Example: `iris` Dataset**"
      ],
      "metadata": {
        "id": "Mo84uYqmtdXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris %>% str()"
      ],
      "metadata": {
        "id": "shJ3rr1etUD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Bivariate Data As A Special Case of Multivariate Data**\n",
        "\n",
        "Bivariate data is a special case where we have two measurements per experimental unit. Bivariate data is useful especially when we want to examine the nature of the relationship between two variables. Bivariate data can be categorical, numerical, or some combination of the two. Note that bivariate data can be extracted from a larger multivariate dataset for the purposes of analyses."
      ],
      "metadata": {
        "id": "G6_becp6tfQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris %>%\n",
        "  select(Sepal.Length, Sepal.Width) %>%\n",
        "  str()"
      ],
      "metadata": {
        "id": "fGaLKzSDtlin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While bivariate data analysis is relatively straightforward, it lays the essential foundation for understanding and applying more advanced multivariate techniques in later units."
      ],
      "metadata": {
        "id": "G5rbptt40L_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bivariate Categorical Data**\n",
        "\n",
        "Bivariate cetegorical data occurs when we have two observations of an experimental unit that are both **categorical variables**. These can be summarised easily and compactly in tables, but also provides some structure to indicate the relationship between the variables.\n",
        "\n"
      ],
      "metadata": {
        "id": "umRdmBh0u3X6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Example: `titanic` Dataset**"
      ],
      "metadata": {
        "id": "dT5DxNtGxA2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset is derived from the well-known `Titanic` dataset, which contains information on 2,201 passengers aboard the Titanic, including their:\n",
        "- Passenger class (`class`)\n",
        "- Sex (`sex`)\n",
        "- Age group (`age_status`, i.e., adult or child)\n",
        "- Survival status (`survived`)\n",
        "\n",
        "We will begin by exploring bivariate relationships between key variables in the dataset to uncover potential associations. Here, we will mostly focus on informal, exploratory summaries ‚Äî no formal statistical tests yet ‚Äî to answer questions like:\n",
        "\n",
        "1. Is there an association between passenger class and survival?\n",
        "2. Is there an association between sex and survival?\n",
        "\n",
        "We will use simple tools like frequency tables and proportions to investigate these relationships. More rigorous analysis techniques will be introduced in the coming weeks.\n"
      ],
      "metadata": {
        "id": "eouwp_oBxOB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic = read.csv(\"./datasets/titanic.csv\", stringsAsFactors = T)\n",
        "titanic %>%\n",
        "  str()\n",
        "\n",
        "titanic %>%\n",
        "  head(5)"
      ],
      "metadata": {
        "id": "BOO0TIoGvm1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Table**\n",
        "\n",
        "Bivariate categorical data can be summarised by a two-dimensional table, often called a contingency table, where:\n",
        "\n",
        "- Each row corresponds to a category of one variable,\n",
        "- Each column corresponds to a category of the other variable,\n",
        "- And each cell contains the count or proportion of observations that fall into that specific combination of categories.\n",
        "\n",
        "To create a contingency table in R, we can use the `table()` function.\n"
      ],
      "metadata": {
        "id": "xT2wMEwwyhjl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Example: `Survived` vs. `Class`**"
      ],
      "metadata": {
        "id": "9aGtevHw0h2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to answer the question:\n",
        "\n",
        "> Is there an association between passenger class and survival?\n",
        "\n",
        "We can create a contingency table to show the relationship between `Survived` and `Class`."
      ],
      "metadata": {
        "id": "uGGjD_ta05dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table(titanic$Class, titanic$Survived)\n",
        "\n",
        "# This gives the same results\n",
        "# titanic %>%\n",
        "#   select(Class, Survived) %>%\n",
        "#   table()"
      ],
      "metadata": {
        "id": "5cZ7geDX0eDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This table displays the raw counts of observations for each combination of categories. We can convert these counts into proportions using the `prop.table()` function, which can take a contingency constructed via `table()` as input."
      ],
      "metadata": {
        "id": "5c1SZa1R1JLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prop.table(table(titanic$Class, titanic$Survived))*100 #*100 for percentage"
      ],
      "metadata": {
        "id": "cYVYXqD211qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, the function `prop.table()` computes the **unconditional proportion**, which is the proportion of individuals in a specific combination of categories relative to the entire population.  For example, around 9% of the passengers were in first class and survived."
      ],
      "metadata": {
        "id": "YOoqM1Vc2KSV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "However, this unconditional proportion may be difficult to interpret, especially when the groups are imbalanced ‚Äî for example, there are usually fewer people in first class than in third class. Such imbalances can obscure the underlying relationship.\n",
        "\n",
        "To address this, we often **normalise by class** (i.e., compute conditional proportions within each class). This expresses the proportion of survivors **within each class**, making it easier to compare survival rates across classes regardless of their sizes. This can be done by setting the `margin` option in `prop.table()`:\n",
        "\n",
        "- `margin = 1`: Normalises by row (i.e., within each class)\n",
        "- `margin = 2`: Normalises by column\n",
        "\n",
        "We will connect this with the idea of conditional probability later in the unit."
      ],
      "metadata": {
        "id": "DP3iwVrX3EEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prop.table(table(titanic$Class, titanic$Survived), margin = 1)*100"
      ],
      "metadata": {
        "id": "DwQFM3gk3k8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, we can see that out of all passengers who were in first class, around 62% survived.  Compare this with say the proportion of third class passengers that survived, which was only around 25%."
      ],
      "metadata": {
        "id": "wiA70DAniiTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is your conclusion üôÇ?**"
      ],
      "metadata": {
        "id": "8leYf6W23PPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Creating Contingency Tables via `dplyr`**\n",
        "\n",
        "We can use the `kable()` function from the `knitr` package to format tables neatly. While it offers many customisation options, we‚Äôll use the default settings for simplicity."
      ],
      "metadata": {
        "id": "htJyjt0S-WPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Raw Counts**"
      ],
      "metadata": {
        "id": "iUiilCjm371M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Long-format contingency table\n",
        "titanic %>%\n",
        "  group_by(Class, Survived) %>%\n",
        "  summarise(Count = n(), .groups = \"drop\") %>%\n",
        "  kable(caption = \"Class vs. Survived (Raw Counts & Long-Format)\")"
      ],
      "metadata": {
        "id": "mTIgZDTQ_xiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic %>%\n",
        "  group_by(Class, Survived) %>%\n",
        "  summarise(Count = n(), .groups = \"drop\") %>%\n",
        "  pivot_wider(\n",
        "    names_from = Survived,\n",
        "    values_from = Count,\n",
        "    values_fill = 0\n",
        "  ) %>%\n",
        "  kable(caption = \"Class vs. Survived (Raw Counts)\")"
      ],
      "metadata": {
        "id": "onyIuqzj-ekg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unnormalised Frequencies/Proportions**"
      ],
      "metadata": {
        "id": "fscQg7cI-vt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic %>%\n",
        "  group_by(Class, Survived) %>%\n",
        "  summarise(Count = n(), .groups = \"drop\") %>%\n",
        "  mutate(Freq = Count / sum(Count)) %>%\n",
        "  select(Class, Survived, Freq)  %>%\n",
        "  kable(caption = \"Class vs. Survived (Unnormalised, Long-Format)\")"
      ],
      "metadata": {
        "id": "XN-0AlXE_v4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic %>%\n",
        "  group_by(Class, Survived) %>%\n",
        "  summarise(Count = n(), .groups = \"drop\") %>%\n",
        "  mutate(Freq = Count / sum(Count)) %>%\n",
        "  select(Class, Survived, Freq) %>%\n",
        "  pivot_wider(\n",
        "    names_from = Survived,\n",
        "    values_from = Freq,\n",
        "    values_fill = 0\n",
        "  ) %>%\n",
        "  kable(caption = \"Class vs. Survived (Unnormalised)\")"
      ],
      "metadata": {
        "id": "UysF_JiA_Ixl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalised Frequencies/Proportions**"
      ],
      "metadata": {
        "id": "7hUHOpbC_SQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic %>%\n",
        "  group_by(Class, Survived) %>%\n",
        "  summarise(Count = n(), .groups = \"drop\") %>%\n",
        "  group_by(Class) %>%\n",
        "  mutate(Freq = Count / sum(Count)) %>% #Here sum(Count) is computed within Class\n",
        "  ungroup() %>%\n",
        "  select(Class, Survived, Freq) %>%\n",
        "  kable(caption = \"Class vs. Survived (Normalised by Class, Long-Format)\")"
      ],
      "metadata": {
        "id": "eD8sZL_b_uMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic %>%\n",
        "  group_by(Class, Survived) %>%\n",
        "  summarise(Count = n(), .groups = \"drop\") %>%\n",
        "  group_by(Class) %>%\n",
        "  mutate(Freq = Count / sum(Count)) %>% #Here sum(Count) is computed within Class\n",
        "  ungroup() %>%\n",
        "  select(Class, Survived, Freq) %>%\n",
        "  pivot_wider(\n",
        "    names_from = Survived,\n",
        "    values_from = Freq,\n",
        "    values_fill = 0\n",
        "  )  %>%\n",
        "  kable(caption = \"Class vs. Survived (Normalised by Class)\")"
      ],
      "metadata": {
        "id": "N6ZwXjGM6VnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Graphical Summaries**\n",
        "\n"
      ],
      "metadata": {
        "id": "SRGuNGv47D_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Bar Chart**\n",
        "\n",
        "There are several options for visualising bivariate categorical data. Among these, bar plots are the most commonly used.\n",
        "\n",
        "We can use `ggplot() %>% geom_bar()` to create bar plots that compare categories across two variables. To display these segments side-by-side (rather than stacked), we add the option `position = \"dodge\"` to `geom_bar()`."
      ],
      "metadata": {
        "id": "ofrKGjgZEd4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One convenient option for creating bar plots is to input the raw dataset directly into `ggplot()`. `geom_bar()` by default counts the number of cases for each `x` value (i.e., it computes frequencies automatically). This is called the statistical transformation (or `stat`) and the default is `stat = \"count\"`."
      ],
      "metadata": {
        "id": "071fE-bO8omz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic %>%\n",
        "  ggplot(aes(x = Class, fill = Survived)) +\n",
        "  geom_bar(stat = \"count\", position = \"dodge\") +\n",
        "  labs(y = \"Count\", title = \"Survival by Class\")"
      ],
      "metadata": {
        "id": "yAJxrIro8bTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another option, which is less convenient but provides greater control, is to manually construct a long-format contingency table."
      ],
      "metadata": {
        "id": "zPN4G_ZlAbUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to set `stat = \"identity\"`. Here, you‚Äôre telling `geom_bar()`:\n",
        "\n",
        "> **‚ÄúDon‚Äôt do any counting ‚Äî just use the y values I provide directly.‚Äù**\n",
        "\n",
        "This means you have to supply the y-values yourself (e.g., counts, proportions, or any numeric variable), and `geom_bar()` will just plot bars with those heights."
      ],
      "metadata": {
        "id": "81KZhmadB7_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic %>%\n",
        "  group_by(Class, Survived) %>%\n",
        "  summarise(Count = n(), .groups = \"drop\") %>%\n",
        "  ggplot(aes(x = Class, y = Count, fill = Survived)) +\n",
        "  geom_bar(stat = \"identity\", position = \"dodge\") +\n",
        "  labs(y = \"Count\", title = \"Survival by Class\")\n"
      ],
      "metadata": {
        "id": "AfmGatazAwpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, these are raw counts, which may be misleading when the groups are unbalanced. We need to normalise the counts within each class to account for class imbalance. Constructing a long-format contingency table gives us the flexibility and control needed to calculate these proportions."
      ],
      "metadata": {
        "id": "rKJ8x1Or9EYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic %>%\n",
        "  group_by(Class, Survived) %>%\n",
        "  summarise(Count = n(), .groups = \"drop\") %>%\n",
        "  group_by(Class) %>%\n",
        "  mutate(Freq = 100*Count / sum(Count)) %>% #Here sum(Count) is computed within Class\n",
        "  ungroup() %>%\n",
        "  select(Class, Survived, Freq) %>%\n",
        "  ggplot(aes(x = Class, y = Freq, fill = Survived)) +\n",
        "  geom_bar(stat = \"identity\", position = \"dodge\") +\n",
        "  labs(y = \"Frequency\", title = \"Survival Frequency by Class\")"
      ],
      "metadata": {
        "id": "AEam_hTw_bhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Mosaic Plot (Optional)**"
      ],
      "metadata": {
        "id": "i3FoC217C312"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mosaic plots are a base R visualisation (available via the `mosaicplot()` function) that directly takes a contingency table as input. They display the joint distribution of two categorical variables by sizing tiles proportionally to counts/frequencies. This makes it easy to spot associations or differences between categories at a glance.\n"
      ],
      "metadata": {
        "id": "i5xR7yDqDK-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Raw Counts**"
      ],
      "metadata": {
        "id": "DXXMCUr6D237"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic %>%\n",
        "  select(Class, Survived) %>%\n",
        "  table() %>%\n",
        "  mosaicplot(main = \"Survival by Class\",\n",
        "             xlab = \"Passenger Class\",\n",
        "             ylab = \"Proportion Survived\",\n",
        "             color = TRUE,\n",
        "             shade = TRUE,\n",
        "             las = 1)"
      ],
      "metadata": {
        "id": "MlitvMPK8wIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalised Frequencies**"
      ],
      "metadata": {
        "id": "gIxnmYsND8Cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic %>%\n",
        "  select(Class, Survived) %>%\n",
        "  table() %>%\n",
        "  prop.table(margin = 1) %>%\n",
        "  multiply_by(100) %>%\n",
        "  mosaicplot(main = \"Survival by Class\",\n",
        "             xlab = \"Passenger Class\",\n",
        "             ylab = \"Proportion Survived\",\n",
        "             color = TRUE,\n",
        "             shade = TRUE,\n",
        "             las = 1)"
      ],
      "metadata": {
        "id": "P3JcF66hD0O7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bivariate Combined Data Types**\n",
        "\n",
        "\n",
        "Combined bivariate data includes both numeric and categorical data, these can be very common datasets to find, and arise from looking at how different factors influence some numerical measurements.\n",
        "\n",
        "For example, in the iris dataset, we can extract the numeric variable `Sepal.Length` and the categorical variable `Species` to create a bivariate dataset combining both types of data.\n"
      ],
      "metadata": {
        "id": "2MNYlPlTESOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris %>%\n",
        "  select(Sepal.Length, Species) %>%\n",
        "  head(5)"
      ],
      "metadata": {
        "id": "p0V779YQEtkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When working with bivariate datasets that combine numeric and categorical variables, some key questions we might want to answer include:\n",
        "\n",
        "1. How does the numeric variable differ across the categories?\n",
        "2. Are there clear patterns or differences in distribution by category?\n",
        "3. Can the categorical variable help explain variability in the numeric variable?\n",
        "4. What summary statistics (mean, median, range) characterise each group?\n",
        "5. Are there outliers or unusual observations within any category?\n",
        "\n",
        "Techniques for formally addressing many of these questions will be introduced later in this unit. For now, we will focus primarily on graphical and informal summaries, especially to explore questions 2 and 4.\n"
      ],
      "metadata": {
        "id": "qrNtLtZcFRBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercises**"
      ],
      "metadata": {
        "id": "pHltOzvDGezt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercise 1**\n",
        "\n",
        "Compute the mean and standard deviation of `Sepal.Length` for each `Species` in the `iris` dataset. Based on these, determine whether the intervals defined by mean ¬± 2 standard deviations overlap between `Species`."
      ],
      "metadata": {
        "id": "E8jyuT7mGvgv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZvJozGHxHZ_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>‚ñ∂Ô∏è Click to show the solution</summary>\n",
        "\n",
        "```r\n",
        "iris %>%\n",
        "  group_by(Species) %>%\n",
        "  summarise(\n",
        "    meanSepalLength = mean(Sepal.Length),\n",
        "    sdSepalLength = sd(Sepal.Length)\n",
        "  ) %>%\n",
        "  ungroup() %>%\n",
        "  mutate(lowerInterval = meanSepalLength - 2*sdSepalLength,\n",
        "         upperInterval = meanSepalLength + 2*sdSepalLength)\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "rYOeMHJzHqpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercise 2**\n",
        "\n",
        "Compare the distributions of `Sepal.Length` across all `Species` in the `iris` dataset using boxplots. Interpret the results."
      ],
      "metadata": {
        "id": "UfV2KJpBH3Oi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DOWBRPpEJBpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>‚ñ∂Ô∏è Click to show the solution</summary>\n",
        "\n",
        "```r\n",
        "iris %>%\n",
        "  ggplot(aes(x = Species, y = Sepal.Length, fill = Species)) +\n",
        "  geom_boxplot() +\n",
        "  labs(title = \"Distribution of Sepal Length by Species\",\n",
        "       x = \"Species\",\n",
        "       y = \"Sepal Length\") +\n",
        "  theme_minimal()\n",
        "\n",
        "# The Sepal Length for Sentosa seems to be smaller than that of Versicolor and\n",
        "# Virginica, since there is no overlap in the interquartile ranges. Indeed,\n",
        "# almost all the Sepal Lengths for Virginica are larger than that for Sentosa,\n",
        "# since there is almost no overlap in their boxolots. The Sepal Length for\n",
        "# Versicolor seems to also be smaller than Virginica, but it is more difficult\n",
        "# to tell as there is a small overlap in the interquartile ranges of the\n",
        "# boxplots. There seems to be an unusually small value of Sepal Length for\n",
        "# Virginica.\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "NX810OsCJFEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercise 3**\n",
        "\n",
        "Compare the distributions of `city` EPA across all `trans` (transmission) types in the `epa_data` dataset using histograms.  Interpret the results.\n",
        "\n",
        "**Hint**: Instead of using `facet_wrap()`, set `position = \"identity\"` in `geom_histogram()` to overlay histograms. Set `alpha = 0.7` (transparency level) for better visibility."
      ],
      "metadata": {
        "id": "dTD7XRpnKBse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epa_data = read.csv(\"./datasets/epa_data.csv\")\n",
        "epa_data %>% head()"
      ],
      "metadata": {
        "id": "HOS5G6C6J0Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FFqaa2bTKXfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>‚ñ∂Ô∏è Click to show the solution</summary>\n",
        "\n",
        "```r\n",
        "epa_data %>%\n",
        "  ggplot(aes(x = city, fill = trans)) +\n",
        "  geom_histogram(aes(y = after_stat(density)),\n",
        "                 bins = 30,\n",
        "                 alpha = 0.7,\n",
        "                 color = \"black\", #border color\n",
        "                 position = \"identity\") +             \n",
        "  labs(title = \"Stacked Normalised City MPG Distribution by Transmission Type\",\n",
        "       x = \"City MPG\",\n",
        "       y = \"Density\",\n",
        "       fill = \"Transmission\") +\n",
        "  theme_minimal()\n",
        "\n",
        "# The City MPG seems to have a similar measure of centrality between Automatic\n",
        "# and Manual, however the City MPG values of Automatic are substantially more\n",
        "# dispersed. In particular, Automatic shows a substantial amount of positive\n",
        "# skewness (skew to the right), whereas the distribution of City MPG values for\n",
        "# Manual is closer to symmetric.\n",
        "\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "L9x7VSsqMbiD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bivariate Numeric Data**\n",
        "\n",
        "Finally, the more interesting part: exploring relationships between two numeric variables. We'll look at scatterplots, correlation, and trend patterns to better understand how two continuous measurements vary together."
      ],
      "metadata": {
        "id": "nrXQr3NDMjVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **Covariance**\n",
        "\n",
        "If sample variance for a numeric vector `x` is defined as:\n",
        "\n",
        "$$\n",
        "s_x^2 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n-1}\n",
        "$$\n",
        "\n",
        "or the \"mean\" of the squared distance between observations, then it follows that covariance is defined as:\n",
        "\n",
        "$$\n",
        "s_{xy} = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{n-1}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $(x_i, y_i)$ is a **paired** observation indexed by $i$.\n",
        "- $\\bar{x}, \\bar{y}$ are the sample means of $x$ and $y$.\n",
        "- $n$ is the number of observations.\n",
        "\n",
        "**By definition, sample variance is the covariance between one variable and itself.**\n"
      ],
      "metadata": {
        "id": "a9wQgjNeMwS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Covariance is a statistical measure that quantifies the degree to which two variables change together. Specifically, it measures the **linear relationship** between two continuous variables.\n",
        "\n",
        "- A **positive covariance** indicates that as one variable increases, the other tends to increase as well.\n",
        "- A **negative covariance** means that as one variable increases, the other tends to decrease.\n",
        "- A covariance close to zero suggests there is little to no linear relationship between the variables.\n"
      ],
      "metadata": {
        "id": "LamWLXVGS3vn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In R, we can use `cov(x,y)` to compute covariance between variables `x` and `y`."
      ],
      "metadata": {
        "id": "vKHJvjfPOLHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Example**\n",
        "\n",
        "Notice that as `city` EPA increases, `hwy` EPA tends to increase."
      ],
      "metadata": {
        "id": "t5uCZDQmPBzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epa_data %>%\n",
        "  ggplot(aes(x = city, y = hwy)) +\n",
        "  geom_point(size = 2)"
      ],
      "metadata": {
        "id": "-XtxFrwHOs80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Their covariance is indeed positive."
      ],
      "metadata": {
        "id": "4hDiirnwPcpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cov(epa_data$city, epa_data$hwy)"
      ],
      "metadata": {
        "id": "jkKlcSB3PYMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that as engine displacement (`disp`) increases, `city` EPA decreases."
      ],
      "metadata": {
        "id": "Oq5h7RtoP1wO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epa_data %>%\n",
        "  ggplot(aes(x = disp, y = city)) +\n",
        "  geom_point(size = 2)"
      ],
      "metadata": {
        "id": "aut2Ve6kPh5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Their covariance is indeed negative."
      ],
      "metadata": {
        "id": "m4UnllI1QRoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cov(epa_data$city, epa_data$disp, use = \"complete.obs\") #use = \"complete.obs\" to ignore incomplete pairs (containing NAs)"
      ],
      "metadata": {
        "id": "VnAR1mgBQGyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Correlation**\n",
        "\n",
        "Covariance tells us the **direction** of the linear relationship between two variables but does **not** tell us how **strong** that relationship is.\n",
        "\n",
        "Additionally, covariance depends on the **units** of measurement (the scale of the data). For example, imagine we no longer measure `city` and `hwy` EPA in miles per gallon (mpg), but instead in kilometers per litre (km/L or kpL). Since the units have changed, the covariance value would also change, making it difficult to compare across different datasets or variables measured on different scales.\n",
        "\n"
      ],
      "metadata": {
        "id": "cyGikjCcQiuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epa_data %>%\n",
        "  mutate(\n",
        "    city_kpL = city * 0.425144,\n",
        "    hwy_kpL = hwy * 0.425144\n",
        "  ) -> epa_data\n",
        "\n",
        "epa_data %>%\n",
        "  select(city, hwy, city, city_kpL, hwy_kpL) %>%\n",
        "  head(5)\n",
        "\n",
        "cov(epa_data$city_kpL, epa_data$hwy_kpL)"
      ],
      "metadata": {
        "id": "8g2PDgmGRf4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need a **standardised summary** that can determine both the **direction** and **strength** of a linear relationship, while also being **unitless** and **comparable across different datasets** or examples $‚ü∂$ correlation coefficient.\n",
        "\n",
        "The **correlation coefficient** $r_{xy}$ between two variables `x` and `y` is given by:\n",
        "\n",
        "$$\n",
        "r_{xy} = \\frac{s_{xy}}{s_x s_y}.\n",
        "$$\n",
        "\n",
        "Thus, correlation is covariance standardised by the product of the variables' standard deviations.\n",
        "\n",
        "The correlation coefficient $r$ always lies between $-1$ and $1$:\n",
        "\n",
        "- $r = 1$ indicates a **perfect positive linear relationship**: as one variable increases, the other increases proportionally.\n",
        "- $r = -1$indicates a **perfect negative linear relationship**: as one variable increases, the other decreases proportionally.\n",
        "- $r = 0$ suggests **no linear relationship** between the variables.\n",
        "\n",
        "In R, we can use the `cor(x,y)` function to computes the correlation between numeric vectors `x` and `y`.\n"
      ],
      "metadata": {
        "id": "AbmdkVKER0JT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Example**\n"
      ],
      "metadata": {
        "id": "ZY1wZQk3S66u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Example 1**\n",
        "Correlation between `city` EPA and `hwy` EPA is the same regardless of the measurement unit."
      ],
      "metadata": {
        "id": "QTeXRJsxTYbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cor(epa_data$city, epa_data$hwy)\n",
        "cor(epa_data$city_kpL, epa_data$hwy)\n",
        "cor(epa_data$city, epa_data$hwy)\n",
        "cor(epa_data$city, epa_data$hwy_kpL)"
      ],
      "metadata": {
        "id": "gLb_AmgwS_H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Example 2**\n"
      ],
      "metadata": {
        "id": "D5Gw0KpDWFrT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have prepared several datasets with different correlation levels to illustrate how the **strength and direction** of the linear relationship between two variables can vary.\n",
        "\n",
        "Each dataset represents a different scenario:\n",
        "\n",
        "- Strong positive correlation\n",
        "- Weak positive correlation\n",
        "- No correlation\n",
        "- Weak negative correlation\n",
        "- Strong negative correlation"
      ],
      "metadata": {
        "id": "uBNtUFq3YbiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strong Positive Linear Relationship**"
      ],
      "metadata": {
        "id": "_cpib9oiXZxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strong_pos = read.csv(\"datasets/strong_pos_linear.csv\")\n",
        "rVal = cor(strong_pos$x, strong_pos$y)\n",
        "\n",
        "strong_pos %>%\n",
        "  ggplot(aes(x = x, y = y)) +\n",
        "  geom_point(size = 3, color = \"black\") +\n",
        "  ggtitle(paste0(\"Strong positive linear relationship: r = \", round(rVal, 3))) +\n",
        "  theme_minimal()"
      ],
      "metadata": {
        "id": "fmeOFsmGXbkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weak Positive Linear Relationship**"
      ],
      "metadata": {
        "id": "L72whsK0XCdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weak_pos = read.csv(\"datasets/weak_pos_linear.csv\")\n",
        "rVal = cor(weak_pos$x, weak_pos$y)\n",
        "\n",
        "weak_pos %>%\n",
        "  ggplot(aes(x = x, y = y)) +\n",
        "  geom_point(size = 3, color = \"black\") +\n",
        "  ggtitle(paste0(\"Weak positive linear relationship: r = \", round(rVal, 3))) +\n",
        "  theme_minimal()"
      ],
      "metadata": {
        "id": "gGQQuT3KXUja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**No Linear Relationship**"
      ],
      "metadata": {
        "id": "yQlY_q_cXn_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_linear = read.csv(\"datasets/no_linear_rel.csv\")\n",
        "rVal = cor(no_linear$x, no_linear$y)\n",
        "\n",
        "no_linear %>%\n",
        "  ggplot(aes(x = x, y = y)) +\n",
        "  geom_point(size = 3, color = \"black\") +\n",
        "  ggtitle(paste0(\"No linear relationship: r = \", round(rVal, 3))) +\n",
        "  theme_minimal()"
      ],
      "metadata": {
        "id": "OaBmf8qWXrRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weak Negative Linear Relationship**"
      ],
      "metadata": {
        "id": "2HrEmsc8WnM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weak_neg = read.csv(\"datasets/weak_neg_linear.csv\")\n",
        "rVal = cor(weak_neg$x, weak_neg$y)\n",
        "\n",
        "weak_neg %>%\n",
        "  ggplot(aes(x = x, y = y)) +\n",
        "  geom_point(size = 3, color = \"black\") +\n",
        "  ggtitle(paste0(\"Weak negative linear relationship: r = \", round(rVal, 3))) +\n",
        "  theme_minimal()"
      ],
      "metadata": {
        "id": "HDn5WonzWUye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strong Negative Linear Relationship**"
      ],
      "metadata": {
        "id": "NvBbwzoZX2_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strong_neg = read.csv(\"datasets/strong_neg_linear.csv\")\n",
        "rVal = cor(strong_neg$x, strong_neg$y)\n",
        "\n",
        "strong_neg %>%\n",
        "  ggplot(aes(x = x, y = y)) +\n",
        "  geom_point(size = 3, color = \"black\") +\n",
        "  ggtitle(paste0(\"Strong negative linear relationship: r = \", round(rVal, 3))) +\n",
        "  theme_minimal()"
      ],
      "metadata": {
        "id": "QZuZ6io2X7Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Least-Squares Line**\n",
        "\n",
        "**To quantify linear relationship** between two variables $x$ and $y$, we can fit a **least-squares regression line** of the form:\n",
        "\n",
        "$$\n",
        "y = \\hat{a} + \\hat{b}x.\n",
        "$$\n",
        "\n",
        "This line minimises the total squared vertical distance between the observed points and the line:\n",
        "\n",
        "$$\n",
        "\\min_{a, b} \\sum_{i=1}^{n} (y_i - a - bx_i)^2.\n",
        "$$\n",
        "\n",
        "The solutions for the slope $\\hat{b}$ and intercept $\\hat{a}$ are:\n",
        "\n",
        "$$\n",
        "\\hat{b} = \\frac{s_{xy}}{s_x^2} = r \\cdot \\frac{s_y}{s_x},\n",
        "$$\n",
        "and\n",
        "$$\n",
        "\\hat{a} = \\bar{y} - \\hat{b}\\bar{x}.\n",
        "$$\n",
        "\n",
        "The **slope** depends on the correlation $r$, and the ratio of the standard deviations of $y$ and $x$, having the same sign as $s_{xy}$ and $r_{xy}$. The **intercept** adjusts to ensure the line passes through the point $(\\bar{x}, \\bar{y})$.\n",
        "\n",
        "In R, we can use the `lm()` function to compute the slope and intercept of the best fitting line."
      ],
      "metadata": {
        "id": "khRbwR5DYU5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Examples**\n"
      ],
      "metadata": {
        "id": "53JF0KeoaFKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Example 1**\n",
        "\n",
        "Given the `strong_pos` dataset that we imported earlier, we can use the `lm()` function in R to compute the slope and intercept of the best-fitting line in a linear regression model.\n",
        "\n",
        "This function expects a formula as input. Here, the formula is written as:\n",
        "\n",
        "```r\n",
        "y ~ x\n",
        "```\n",
        "This means we want to fit a linear model of the form:\n",
        "$$y = ax + b$$"
      ],
      "metadata": {
        "id": "NmtMn_TxaiIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strong_pos %>%\n",
        "  lm(formula = y~x)"
      ],
      "metadata": {
        "id": "UIbjiVPoaEUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course, we can also manually compute these quantities."
      ],
      "metadata": {
        "id": "hAOi1TVYa-iN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_x = mean(strong_pos$x)\n",
        "mean_y = mean(strong_pos$y)\n",
        "s_xy = cov(strong_pos$x, strong_pos$y)\n",
        "s_x = var(strong_pos$x)\n",
        "\n",
        "b_hat = s_xy/s_x\n",
        "a_hat = mean_y - mean_x*b_hat\n",
        "b_hat\n",
        "a_hat"
      ],
      "metadata": {
        "id": "MWOk3Bn4bHVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Example 2**\n",
        "\n",
        "It is possible to overlay the best-fitting line on a scatter plot created with ggplot using `geom_smooth(method = \"lm\", se = FALSE)`. If we set `se = TRUE`, it will display confidence bands surrounding the fitted line, providing some \"uncertainty quantification.\" We will learn what confidence intervals are later in this unit.\n"
      ],
      "metadata": {
        "id": "6ImAJiIJbwSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Without Confidence Bands**"
      ],
      "metadata": {
        "id": "E18YJR_Di7jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strong_neg %>%\n",
        "  ggplot(aes(x = x, y = y)) +\n",
        "  geom_point(size = 3, color = \"black\") +\n",
        "  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +  # best-fitting line\n",
        "  theme_minimal()\n"
      ],
      "metadata": {
        "id": "neYME4tEcJvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**With Confidence Bands**"
      ],
      "metadata": {
        "id": "Oy_dght0i-sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strong_neg %>%\n",
        "  ggplot(aes(x = x, y = y)) +\n",
        "  geom_point(size = 3, color = \"black\") +\n",
        "  geom_smooth(method = \"lm\", se = TRUE, color = \"red\") +  # best-fitting line\n",
        "  theme_minimal()\n"
      ],
      "metadata": {
        "id": "lTYJj6GWiiUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`weak_neg` Example**"
      ],
      "metadata": {
        "id": "HUzK2HeDi_4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat the same analysis process for the `weak_neg` example. We observe a negative linear relationship between `x` and `y`, but the confidence bands are now wider. This is consistent with the weak correlation coefficient."
      ],
      "metadata": {
        "id": "_Gs9AZq1h3iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weak_neg %>%\n",
        "  ggplot(aes(x = x, y = y)) +\n",
        "  geom_point(size = 3, color = \"black\") +\n",
        "  geom_smooth(method = \"lm\", se = TRUE, color = \"red\") +  # best-fitting line\n",
        "  theme_minimal()\n"
      ],
      "metadata": {
        "id": "unJxGuTfhh4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise**\n",
        "\n",
        "Repeat the same analysis steps for the dataset `weak_pos`:\n",
        "\n",
        "1. Fit a linear regression model using `lm(y ~ x)`\n",
        "2. Manually compute the slope and intercept of the best-fitting line for comparision.\n",
        "3. Plot the data and the regression line with confidence bands using `ggplot2`.\n"
      ],
      "metadata": {
        "id": "DkT7n0vRevqA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1-kZroZefyYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>‚ñ∂Ô∏è Click to show the solution</summary>\n",
        "\n",
        "```r\n",
        "#1\n",
        "\n",
        "weak_pos %>%\n",
        "  lm(formula = y~x)\n",
        "\n",
        "#2\n",
        "\n",
        "mean_x = mean(weak_pos$x)\n",
        "mean_y = mean(weak_pos$y)\n",
        "s_xy = cov(weak_pos$x, weak_pos$y)\n",
        "s_x = var(weak_pos$x)\n",
        "\n",
        "b_hat = s_xy/s_x\n",
        "a_hat = mean_y - mean_x*b_hat\n",
        "b_hat\n",
        "a_hat\n",
        "\n",
        "#3\n",
        "\n",
        "weak_pos %>%\n",
        "  ggplot(aes(x = x, y = y)) +\n",
        "  geom_point(size = 3, color = \"black\") +\n",
        "  geom_smooth(method = \"lm\", se = TRUE, color = \"red\") +  # best-fitting line\n",
        "  theme_minimal()\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "W9wn63pLf3GS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Workshop Questions**"
      ],
      "metadata": {
        "id": "GC67xVlGgAfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 1**\n",
        "\n",
        "Given the `titanic `dataset, use the techniques and R commands you have learned in this workshop to:\n",
        "- Create raw, unnormalised, and normalised contingency tables (based on `Class`) to show the association between passenger class (`Class`) and sex (`Sex`).\n",
        "- Visualise the data using bar plots."
      ],
      "metadata": {
        "id": "Z1RPuNPKjgCd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U42iNjrijySp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>‚ñ∂Ô∏è Click to show the solution </summary>\n",
        "\n",
        "Solution will be released at the end of the week!\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "TjUGBMm_lr8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **EPA Fuel Economy Dataset**\n",
        "\n",
        "A dataset containing information on over 13,500 cars sold in the US from 2010 to 2020, including measurements and characteristics related to vehicle fuel economy and specifications. Data sourced from the [US Fuel Economy website](https://www.fueleconomy.gov/feg/download.shtml).\n",
        "\n",
        "| Variable | Description                                    |\n",
        "|----------|------------------------------------------------|\n",
        "| `city`   | EPA measured fuel economy in miles per gallon (city driving) |\n",
        "| `hwy`    | EPA measured fuel economy in miles per gallon (highway driving) |\n",
        "| `cyl`    | Number of cylinders in the engine              |\n",
        "| `disp`   | Engine displacement (litres)                    |\n",
        "| `drive`  | Vehicle drivetrain layout (e.g., FWD, RWD, AWD) |\n",
        "| `make`   | Vehicle manufacturer name                       |\n",
        "| `model`  | Vehicle model name                              |\n",
        "| `trans`  | Transmission type (manual or automatic)        |\n",
        "| `year`   | Vehicle model year                              |\n"
      ],
      "metadata": {
        "id": "tm4zkzZwI6dO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 2**\n",
        "\n",
        "Compare the distributions of city and highway fuel economy (`city` and `hwy)` for different drivetrain layouts (`drive`).\n",
        "\n",
        "**Hint**: To do this, you can create boxplots showing the distribution of fuel economy values separately for `city` and `hwy` mpg, faceted by `drive` type."
      ],
      "metadata": {
        "id": "gvKglfZ9I9w8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SS6Mb1BbI-Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>‚ñ∂Ô∏è Click to show the solution</summary>\n",
        "\n",
        "```r\n",
        "Solution will be released at the end of the week!\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "eQYlpYLvJAEU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 3**\n",
        "\n",
        "Given the `epa_data` dataset, do the following tasks:\n",
        "\n",
        "- Calculate the correlation between:\n",
        "    - `city` and `disp`\n",
        "    - `hwy` and `disp`  \n",
        "\n",
        "Use an appropriate method to handle any missing values.\n",
        "- Create separate scatter plots of `disp` against mileage values for `city` and `hwy`, with points colored by mileage type (`city` or `hwy`).\n",
        "- Overlay the plots with linear regression lines (with confidence bands).\n",
        "\n",
        "**Hint**: We need a long-format dataset."
      ],
      "metadata": {
        "id": "F5_blDGhJB0C"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iJjsS_PoJFF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>‚ñ∂Ô∏è Click to show the solution</summary>\n",
        "\n",
        "```r\n",
        "Solution will be released at the end of the week!\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "3gXOlWPpJFWV"
      }
    }
  ]
}