{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Week 6: Sampling Methods**\n",
        "\n",
        "```\n",
        ".------------------------------------.\n",
        "|   __  ____  ______  _  ___ _____   |\n",
        "|  |  \\/  \\ \\/ / __ )/ |/ _ \\___  |  |\n",
        "|  | |\\/| |\\  /|  _ \\| | | | | / /   |\n",
        "|  | |  | |/  \\| |_) | | |_| |/ /    |\n",
        "|  |_|  |_/_/\\_\\____/|_|\\___//_/     |\n",
        "'------------------------------------'\n",
        "\n",
        "```\n",
        "\n",
        "In this workshop, we will study common sampling methods and sampling distributions, and examine the asymptotic distribution of the sample mean as the sample size increases."
      ],
      "metadata": {
        "id": "ZtpJJ8BSHOaK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pre-Configurating the Notebook**"
      ],
      "metadata": {
        "id": "SVtkEkRDY5Ex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Switching to the R Kernel on Colab**\n",
        "\n",
        "By default, Google Colab uses Python as its programming language. To use R instead, you’ll need to manually switch the kernel by going to **Runtime > Change runtime type**, and selecting R as the kernel. This allows you to run R code in the Colab environment.\n",
        "\n",
        "However, our notebook is already configured to use R by default. Unless something goes wrong, you shouldn’t need to manually change runtime type."
      ],
      "metadata": {
        "id": "0vfwHxobY6_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importing Required Packages**\n",
        "**Run the following lines of code**:"
      ],
      "metadata": {
        "id": "36rWeG2RY7fJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Do not modify\n",
        "\n",
        "setwd(\"/content\")\n",
        "\n",
        "# Remove `MXB107-Notebooks` if exists,\n",
        "if (dir.exists(\"MXB107-Notebooks\")) {\n",
        "  system(\"rm -rf MXB107-Notebooks\")\n",
        "}\n",
        "\n",
        "# Fork the repository\n",
        "system(\"git clone https://github.com/edelweiss611428/MXB107-Notebooks.git\")\n",
        "\n",
        "# Change working directory to \"MXB107-Notebooks\"\n",
        "setwd(\"MXB107-Notebooks\")\n",
        "\n",
        "#\n",
        "invisible(source(\"R/preConfigurated.R\"))"
      ],
      "metadata": {
        "id": "t_2d_ItyY9yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do not modify the following**"
      ],
      "metadata": {
        "id": "q-ITFB1qY_ZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (!require(\"testthat\")) install.packages(\"testthat\"); library(\"testthat\")\n",
        "\n",
        "test_that(\"Test if all packages have been loaded\", {\n",
        "\n",
        "  expect_true(all(c(\"ggplot2\", \"tidyr\", \"dplyr\", \"stringr\", \"magrittr\", \"knitr\") %in% loadedNamespaces()))\n",
        "\n",
        "})"
      ],
      "metadata": {
        "id": "Hgh75IDpZCf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Observational versus Experimental Data**\n"
      ],
      "metadata": {
        "id": "zfDrKa8z1hNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Experimental Data**\n",
        "\n",
        "- The gold standard for collecting data is through a designed experiment, typically a randomized controlled trial (RCT).\n",
        "\n",
        "- Subjects are selected and then randomly assigned either the treatment or a control (e.g. a placebo) and subjected to identical experimental conditions.\n",
        "\n",
        "- As a result the effects of any other factors that might affect the experimental outcome are “cancelled” out across the treatment and control groups.\n",
        "\n",
        "- Experimental outcomes can be assumed to be causally related to the treatment, i.e. one can infer that the variation is caused by the treatment, not merely correlated.\n",
        "\n",
        "- Data collected in there circumstances is referred to as experimental data."
      ],
      "metadata": {
        "id": "PUujp93I2JU5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Observational Data**\n",
        "\n",
        "- In cases where it is impractical or impossible to design and conduct an experiment, researchers have to rely on observational data collected by observation rather than design.\n",
        "\n",
        "- Example of this include the use of historic data sets (actually all data is historic) like government records.\n",
        "- Observational data are typically much more common and much easier to obtain in comparison to experimental data."
      ],
      "metadata": {
        "id": "3OrAl4Sm2KSV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Finite-Population Non-Probability Sampling**\n",
        "\n",
        "In this section, we will explore non-probability sampling through a series of practical discussion questions, rather than exercises or programming examples.\n"
      ],
      "metadata": {
        "id": "lUE974i7SwQ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Non-Probability Sampling Schemes**\n",
        "\n",
        "Non-probability sampling is a method of selecting units from a population through non-random, subjective procedures. This approach does not require a complete sampling frame — a list of all units in the population — making it relatively fast, convenient, and cost-effective. However, because selection is not random, the resulting sample may not accurately represent the population, and any inferences drawn are subject to potential (non-quantifiable) bias.\n",
        "\n",
        "Common forms of non-probability sampling include sequential sampling, convenience sampling, snowball sampling, quota sampling, and purposive sampling, each of which has distinct characteristics and limitations. In particular:\n",
        "\n",
        "- **Sequential sampling**: Samples are selected periodically from a list of potential subjects, taken one after another in sequence. These schemes sometimes resemble random sampling but lack true randomness.\n",
        "- **Convenience sampling**: Subjects are chosen because they are easiest to reach, or they self-select to participate (e.g., IMDB user rankings). However, results are often unreliable due to self-selection bias.\n",
        "- **Snowball sampling**: Similar to convenience sampling, except participants are asked to refer others to the study. This can expand the sample but still suffers from self-selection bias.\n",
        "- **Quota sampling**: Aims to ensure demographic balance by filling pre-set quotas (e.g., 50% male, 50% female). While designed to improve representativeness, it is not random and risks over- or under-representing subgroups.\n",
        "- **Purposive sampling**: Participants are deliberately selected because they fit specific characteristics or criteria relevant to the study (e.g., interviewing only experts on climate change). This method can provide rich insights but is vulnerable to researcher bias and lacks generalisability."
      ],
      "metadata": {
        "id": "G8y-DuwOJtsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercise**\n",
        "\n",
        "Can you think of an example where snowball sampling might be useful?\n",
        "\n",
        "Studying the experiences of undocumented immigrants in a city can be challenging, as these individuals are often difficult to identify and may avoid official records out of fear of legal consequences."
      ],
      "metadata": {
        "id": "N_shPzE_J8Iw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Free Swimming Tickets for Everyone**\n",
        "\n",
        "A city council wants to evaluate the health benefits of a new policy that provides free swimming tickets to residents. Participants are given tickets, and their resting heart rate is recorded before the program begins and after one year. All participants attend the sessions regularly, with no dropouts. After analysing the data, the council observes no substantial improvement in resting heart rate."
      ],
      "metadata": {
        "id": "9shEZZWiJP8F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question 1**\n",
        "\n",
        "What type of sampling method was used in this consultation?\n",
        "\n",
        "Convenience sampling -- they are self-selecting to participate"
      ],
      "metadata": {
        "id": "4JZt7bGgJfyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question 2**\n",
        "\n",
        "What are the potential problems with this sampling approach?\n",
        "\n",
        "Several problems can arise from this approach:\n",
        "\n",
        "- People who accept free swimming tickets may already be health-conscious, physically active, or motivated to improve their fitness.\n",
        "- Those who are less active or indifferent may ignore the offer, so the sample does not represent the general population."
      ],
      "metadata": {
        "id": "tKiADl0qJ5PE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question 3**\n",
        "\n",
        "What biases could affect conclusions drawn from this online consultation?\n",
        "\n",
        "- Self-selection bias / voluntary response bias: People who chose to participate in the swimming program may differ systematically from the general population (e.g., already health-conscious or motivated). The observed lack of heart rate improvement may not reflect the effect on the entire population.\n",
        "- Coverage bias: Residents who did not accept the free tickets or were unaware of the program were excluded from the study."
      ],
      "metadata": {
        "id": "mng8Y6LvLpSv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **84% Want Europe to Stop Changing the Clock**\n",
        "\n",
        "In 2018, the European Commission conducted a public consultation on whether to end the bi-annual clock change across Europe. The consultation ran online from 4 July to 16 August and received 4.6 million responses from all 28 Member States, the highest number ever received for any Commission consultation. According to preliminary results, 84% of respondents favored stopping the clock changes, and 76% described the experience of changing clocks twice a year as “negative” or “very negative.” (see the press release [Summertime Consultation: 84% want Europe to stop changing the clock](https://ec.europa.eu/commission/presscorner/detail/en/ip_18_5302) for more details).\n",
        "\n",
        "![Which of the following alternatives would you favour?](http://ec.europa.eu/avservices/avs/files/video6/repository/prod/photo/store/store2/9/P037989-973692.jpg)\n",
        "\n",
        "\n",
        "![What is your overall experience with the clock change?](http://ec.europa.eu/avservices/avs/files/video6/repository/prod/photo/store/store2/9/P037989-904263.jpg)\n",
        "\n"
      ],
      "metadata": {
        "id": "CN7P2KixuXHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question 1**\n",
        "\n",
        "What type of sampling method was used in this consultation?\n",
        "\n",
        "Convenience sampling -- they are self-selecting to participate"
      ],
      "metadata": {
        "id": "2EDrL0h-rNbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question 2**\n",
        "\n",
        "Why might the results not accurately represent the views of all European citizens?\n",
        "\n",
        "- European citizens who are highly motivated or have strong opinions about the clock change (especially those annoyed by it) were more likely to respond.\n",
        "- Many citizens who are indifferent or less engaged may not have participated."
      ],
      "metadata": {
        "id": "I-li3bCYxb-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question 3**\n",
        "\n",
        "What biases could affect conclusions drawn from this online consultation?\n",
        "\n",
        "- Self-selection bias/voluntary response bias: Strong opinions are overrepresented. The 84% figure likely overestimates support for ending clock changes compared to the general population.\n",
        "- Coverage bias: Citizens without internet access or awareness of the consultation were excluded.\n",
        "\n",
        "While the survey collected millions of responses, the large sample size does not guarantee representativeness. Any conclusions drawn should be treated cautiously."
      ],
      "metadata": {
        "id": "I2P1TAxxxm9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Question 4**\n",
        "\n",
        "Can you think of an example of a survey that might suffer from the same type of bias as the online consultation?\n",
        "\n",
        "An online survey titled \"Who Do You Think Will Win the Next US Election?\" published on the website of a political party. Respondents are likely to be party supporters, which can lead to an overrepresentation of strong opinions and a sample that does not accurately reflect the views of the general population."
      ],
      "metadata": {
        "id": "D8GGr-V3BoTF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Finite-Population Probability Sampling**"
      ],
      "metadata": {
        "id": "CI7fcDcCCfS6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the sampling frame is available, we can use a **probability-based** sampling method, where the probability of selecting each observation is known in advance. As a result, it is possible to quantify bias, as well as evaluate, validate, and compare different sampling methods. Details on this topic are beyond the scope of this unit."
      ],
      "metadata": {
        "id": "uRSwRlB3_o-e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Simple Random Sampling**\n",
        "\n",
        "\n",
        "Simple random sampling (SRS) is a common method where each unit in the population has an equal chance of being selected, and all possible samples of a given size are equally likely.\n",
        "\n",
        "\n",
        "There are two main SRS schemes:\n",
        "- SRS Without Replacement (SRSWOR): Each unit in the population can be selected only once. Once a unit is chosen, it is removed from the pool of possible selections.\n",
        "- SRS With Replacement (SRSWR): Each unit can be selected multiple times, independently of previous selections. This means that after a unit is chosen, it is “put back” into the population, so it is still available for subsequent draws.\n",
        "\n",
        "SRSWR is a bit less efficient than SRSWOR as it may select the same observation multiple times. However, SRSWR is mathematically simpler to work with because each draw is independent."
      ],
      "metadata": {
        "id": "ArLD0a3lCjvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Mean Estimation**\n",
        "\n",
        "For a simple random sample of size $n$ with observations $x_1, x_2, \\dots, x_n$ (from a population $X$ of size $N$), the **sample mean** is  \n",
        "\n",
        "$$\n",
        "\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i.\n",
        "$$\n",
        "\n",
        "This is an **unbiased estimator** of population mean if the sampling frame is complete."
      ],
      "metadata": {
        "id": "YT_DmHXFCKvG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **R Examples**\n",
        "\n",
        "To perform simple random sampling in R, we can use the `sample(x, size, replace, prob)` function, where:\n",
        "\n",
        "- `x`: a vector of values to sample from\n",
        "- `size`: the number of items to select\n",
        "- `replace`: whether or not to perform sampling with replacement. By default, `replace = FALSE`.\n",
        "- `prob`: an optional vector of probability weights for elements in `x`. By default, all elements are equally likely.\n",
        "\n",
        "If `replace = TRUE`, `size` cannot be greater than `length(x)`.\n",
        "\n",
        "The `sample()` function does not work directly on data frames. Take the `iris` dataset as an example."
      ],
      "metadata": {
        "id": "T2vppVxfRpD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris %>%\n",
        "  str()"
      ],
      "metadata": {
        "id": "iNOedfZ7phFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose we want to select 6 observations from `iris` using SRSWOR. First, we need to sample the row indices using `sample()`."
      ],
      "metadata": {
        "id": "3HWHNSNDpk2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(1)\n",
        "nr = nrow(iris)\n",
        "rowIdx = 1:nr\n",
        "smplIdx = sample(rowIdx, 6)\n",
        "smplIdx %>% print()"
      ],
      "metadata": {
        "id": "c8BOfaWrhNQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we can use these indices to extract the corresponding rows."
      ],
      "metadata": {
        "id": "EPh4DQCjpzTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris %>%\n",
        "  slice(smplIdx)"
      ],
      "metadata": {
        "id": "tZ72kco4nFyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `dplyr` package provides a built-in function called `slice_sample()`, which allows you to perform row-wise sampling directly on a data frame, similar to `sample()`."
      ],
      "metadata": {
        "id": "KX98Lvnrq245"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(1)\n",
        "iris %>%\n",
        "  slice_sample(n = 6, replace = FALSE)"
      ],
      "metadata": {
        "id": "pQFQLHr0rMbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another option is to use `sample_n()`, which is older and now soft-deprecated. Unlike `slice_sample()`, however, `sample_n()` allows the use of `n()` within its call."
      ],
      "metadata": {
        "id": "Ad6atqSbSToW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(1)\n",
        "iris %>%\n",
        "  sample_n(size = 6, replace = FALSE)"
      ],
      "metadata": {
        "id": "Z1mf_6UiTCPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(1)\n",
        "iris %>%\n",
        "  sample_n(size = 1/25*n(), replace = FALSE)"
      ],
      "metadata": {
        "id": "eswtSSjzTROz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercise**\n",
        "\n",
        "Planet Zog has 1,250 citizens, divided into 9 districts. The locations `(x,y)` of each citizen and their district are stored in the `planetZog` dataset.\n",
        "\n",
        "- Count the number of citizens in each district.\n",
        "- The planet wants to randomly select 25 citizens from Zog to respond to a survey. Use SRSWOR and save the resulting data frame as `smpl_Zog`.\n",
        "- Visualise the locations of the citizens using `geom_point()`, coloured by `District`.\n",
        "- Overlay the sampled data points, displayed in `black` colour, on the existing plot.\n",
        "- Repeat the sampling process several times and observe the results. What problem do you notice with this sampling approach?\n",
        "\n",
        "**Hint**: You can use a different dataset in `geom_point()` via the `data` argument, specify a separate `aes()` and `colour` for it, and overlay layers by stacking multiple `geom_point()` blocks.”"
      ],
      "metadata": {
        "id": "Rle5UujFsiIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "planetZog = read.csv(\"./datasets/zog_planet.csv\")\n",
        "planetZog %>% str()"
      ],
      "metadata": {
        "id": "MsVX0fKzz2Ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "planetZog = read.csv(\"./datasets/zog_planet.csv\")\n",
        "\n",
        "planetZog %>%\n",
        "  group_by(District) %>%\n",
        "  summarise(nrCitizens = n()) %>%\n",
        "  kable()\n",
        "\n",
        "planetZog %>%\n",
        "  slice_sample(n = 25) -> smpl_Zog\n",
        "\n",
        "planetZog %>%\n",
        "  ggplot(aes(x = x, y = y, colour = District)) +\n",
        "  geom_point(size = 2) +\n",
        "  geom_point(data = smpl_Zog, aes(x = x, y = y), colour = \"black\", size = 3)"
      ],
      "metadata": {
        "id": "89SEQ1Q7LhyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running the sampling several times, you will observe that:\n",
        "- The number of selected observations from each district is not proportional to that district’s population size.\n",
        "- Quite often, some districts end up with zero selected citizens."
      ],
      "metadata": {
        "id": "SyrMatovK1aG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Stratified Random Sampling**\n",
        "\n",
        "Stratified random sampling (StRS) is a method in which the population is first divided into non-overlapping subgroups, called strata, that are ideally internally homogeneous with respect to some characteristic and heterogeneous between strata. Within each stratum, a random sample is then drawn, often using SRS (usually without replacement).\n",
        "\n",
        "This approach ensures representation from all subgroups and can improve precision compared to simple random sampling.\n",
        "\n",
        "There are two main ways to allocate the sample across strata:\n",
        "\n",
        "- Proportional allocation: The sample size from each stratum is proportional to the stratum’s population size. This preserves the overall population structure.\n",
        "- Equal or optimal allocation: The sample sizes may be adjusted based on variability within strata or for specific analysis goals.\n",
        "\n",
        "Sometimes, the stratum sample size $n_h$ is not an integer and needs to be rounded, typically using the ceiling function. As a result, the total sample size may not be exactly $n$, but it will be close.\n",
        "\n",
        "We will only focus on proportional allocation in this workshop."
      ],
      "metadata": {
        "id": "bSrQWpcRNGnX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Mean Estimation**\n",
        "\n",
        "Suppose a population of size $N$ is divided into $H$ strata, with stratum $h$ having size $N_h$. From each stratum, we draw a simple random sample of size $n_h$, giving observations $x_{h1}, x_{h2}, \\dots, x_{h n_h}, h = 1, 2, \\dots, H.$\n",
        "\n",
        "The stratified sample mean is\n",
        "\n",
        "$$\n",
        "\\bar{x}_{\\text{st}} = \\sum_{h=1}^{H} \\frac{N_h}{N} \\bar{x}_h,\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\n",
        "\\bar{x}_h = \\frac{1}{n_h} \\sum_{i=1}^{n_h} x_{hi}\n",
        "$$\n",
        "\n",
        "is the sample mean within stratum $h$, and $N = \\sum_{h=1}^H N_h$ is the total population size.\n",
        "\n",
        "This is an **unbiased estimator** of population mean if the sampling frame is complete."
      ],
      "metadata": {
        "id": "MlYSmCaxGB5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **R Examples**\n",
        "\n",
        "There is no built-in function for stratified random sampling in R. One option is to create sub-datasets for different strata and perform SRS on each of these.\n",
        "\n",
        "Back to the `iris` example. Suppose we want to randomly select 6 observations. Since the dataset contains 3 species with equal numbers of observations, we might want to select 2 observations from each species. In this case, stratified random sampling can be used to ensure that the sample is balanced across species."
      ],
      "metadata": {
        "id": "mLkYMe9TIQzj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we create sub-datasets for different iris species."
      ],
      "metadata": {
        "id": "VlKkJrRaKdDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris %>% select(Species) %>% unique() %>% print()\n",
        "iris %>% filter(Species == \"setosa\") -> setosa\n",
        "iris %>% filter(Species == \"versicolor\") -> versicolor\n",
        "iris %>% filter(Species == \"virginica\") -> virginica"
      ],
      "metadata": {
        "id": "IgvM4Y-HKD0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, SRSWOR is performed within each species."
      ],
      "metadata": {
        "id": "KsklpnvLKhn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "setosa %>% slice_sample(n = 2) -> smpl_setosa\n",
        "versicolor %>% slice_sample(n = 2) -> smpl_versicolor\n",
        "virginica %>% slice_sample(n = 2) -> smpl_virginica"
      ],
      "metadata": {
        "id": "8EQqYRIgKmta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is clear that this method becomes time-consuming and cumbersome when there are many strata. Fortunately, we can use `group_by() %>% slice_sample()` to perform stratified random sampling efficiently."
      ],
      "metadata": {
        "id": "HmLal7I4Lkx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris %>%\n",
        "  group_by(Species) %>%\n",
        "  slice_sample(n=2)"
      ],
      "metadata": {
        "id": "zOw6glSpL8g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One particular disadvantage of `slice_sample()` is that it requires `n` to be a constant. On the other hand, `sample_n()` is more flexible and allows different stratum sample sizes."
      ],
      "metadata": {
        "id": "Qosnjr3BT6mu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercises**"
      ],
      "metadata": {
        "id": "eUZ9YEJZNWP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Exercise 1**\n",
        "\n",
        "The dataset `iris_unbalanced` is extracted from the original `iris` dataset. In this version, the number of observations for each species is no longer equal.\n",
        "\n",
        "Write R code to perform StRS with proportional allocation to select 20 observations from `iris_unbalanced`"
      ],
      "metadata": {
        "id": "1qSIKdZBNYTY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hint**:\n",
        "- Assign the number of observations in `iris_unbalanced` to a variable.\n",
        "- Use the `ceiling(x)` function to compute the ceiling value of `x`.\n",
        "-  `n()` cannot be used within `slice_sample()`."
      ],
      "metadata": {
        "id": "3ChONAA8O3eB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris_unbalanced= read.csv(\"./datasets/iris_unbalanced.csv\")\n",
        "iris_unbalanced %>% str()"
      ],
      "metadata": {
        "id": "nHsylBDpNVa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = nrow(iris_unbalanced)\n",
        "smplSize = 20\n",
        "\n",
        "iris_unbalanced %>%\n",
        "  group_by(Species) %>%\n",
        "  sample_n(size = ceiling(smplSize*n()/N)) -> smpl_iris_unbalanced"
      ],
      "metadata": {
        "id": "MBCogBowOppK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Exercise 2**\n",
        "\n",
        "\n",
        "Zog citizens are not happy with the previous sampling method. They request that the number of selected citizens from each district be proportional to the district’s population size.\n",
        "- Choose an appropriate sampling method in R to carry out this task.\n",
        "- Use the resulting sample to estimate the average population height.\n",
        "\n",
        "**Hint**: Create a new column storing the stratum sizes."
      ],
      "metadata": {
        "id": "sN4UMVfjVFMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = nrow(planetZog)\n",
        "smplSize = 25\n",
        "\n",
        "planetZog %>%\n",
        "  group_by(District) %>%\n",
        "  mutate(Nh = n()) %>% #stratum sizes\n",
        "  sample_n(size = ceiling(smplSize*n()/N)) %>%\n",
        "  summarise(stratumAvgHeight = mean(Height),\n",
        "            Nh = Nh[1]) %>%\n",
        "  ungroup() %>%\n",
        "  summarise(popAvgHeight = sum(stratumAvgHeight*Nh)/sum(Nh))"
      ],
      "metadata": {
        "id": "cZjXp_h1XCk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cluster Sampling**\n",
        "\n",
        "In one-stage cluster sampling, the population is divided into non-overlapping clusters, and a random sample of clusters is selected (typically using SRSWOR). All units within the chosen clusters are included in the sample.\n",
        "\n",
        "If desired, one can also perform SRS within clusters, which leads to two-stage cluster sampling.\n",
        "\n",
        "- This method is simple and cost-effective, especially for populations that are large or geographically dispersed.\n",
        "- Cluster sampling is generally less efficient than SRS or stratified random sampling (this is beyond the scope of this unit)."
      ],
      "metadata": {
        "id": "Mx5hFnffNDA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Mean Estimation**\n",
        "\n",
        "Suppose a population of size $N$ is divided into $C$ clusters, with cluster $c$ having size $M_c$. From the population, we draw a simple random sample of $n_c$ clusters, giving observations\n",
        "\n",
        "$$\n",
        "x_{c1}, x_{c2}, \\dots, x_{c M_c}, \\quad c = 1, 2, \\dots, n_c.\n",
        "$$\n",
        "\n",
        "The **one-stage cluster sample mean** is\n",
        "\n",
        "$$\n",
        "\\bar{x}_{\\text{cluster}} = \\frac{1}{n_c} \\sum_{c=1}^{n_c} \\bar{x}_c,\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\n",
        "\\bar{x}_c = \\frac{1}{M_c} \\sum_{i=1}^{M_c} x_{ci}\n",
        "$$\n",
        "\n",
        "is the mean of all units within the selected cluster $c$.  \n",
        "\n",
        "This is an **unbiased estimator** of the population mean if the clusters are randomly selected and the sampling frame is complete.\n",
        "\n",
        "The formula for two-stage cluster sample mean is generally similar, except that we compute sample mean within each cluster instead.\n"
      ],
      "metadata": {
        "id": "tV9_2dKSbRIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **R Example**\n",
        "\n",
        "Cluster sampling is somewhat more involved than SRS or StRS in terms of implementation. One-stage cluster sampling is straightforward: we first select the clusters and then include all units within those clusters.\n",
        "\n",
        "For two-stage cluster sampling, an additional step is required, where a sample of units is drawn from each selected cluster."
      ],
      "metadata": {
        "id": "Do8KltQebu8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One-stage cluster sampling**:"
      ],
      "metadata": {
        "id": "yr5tBHFGdRK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(1)\n",
        "#Randomly select 3 districts\n",
        "#Use `pull()` to extract `District` as a vector\n",
        "planetZog %>% distinct(District) %>% sample_n(size = 3) %>% pull(District) -> selectedDistricts\n",
        "\n",
        "planetZog %>%\n",
        "  filter(District %in% selectedDistricts) -> smpl_Zog"
      ],
      "metadata": {
        "id": "IAcn79BQcp3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Two-stage cluster sampling**:"
      ],
      "metadata": {
        "id": "QFJwIPYAdT3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(1)\n",
        "#Randomly select 3 districts\n",
        "planetZog %>% distinct(District) %>% sample_n(size = 3) %>% pull(District) -> selectedDistricts\n",
        "\n",
        "#Randomly select 5 observations within each selected district\n",
        "planetZog %>%\n",
        "  filter(District %in% selectedDistricts) %>%\n",
        "  group_by(District) %>%\n",
        "  sample_n(size = 5) -> smpl_Zog"
      ],
      "metadata": {
        "id": "rTNVA-wZdVQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **i.i.d. Sampling**\n",
        "\n",
        "\n",
        "In most classical sampling scenarios, we assume that the observations in a sample are **independent and identically distributed (i.i.d.)**.  \n",
        "\n",
        "- **Independent**: the value of one observation does not affect another.  \n",
        "- **Identically distributed**: all observations come from the same underlying population distribution.  \n",
        "\n",
        "Formally, if $X_1, X_2, \\dots, X_n$ are i.i.d. random variables from population $X$, then each $X_i \\sim F_X$ and  \n",
        "\n",
        "$$\n",
        "P(X_1 \\le x_1, \\dots, X_n \\le x_n) = \\prod_{i=1}^{n} P(X_i \\le x_i).\n",
        "$$  \n",
        "\n",
        "An example of i.i.d. sampling is SRSWR, where we repeatedly draw units from the same finite population, and each draw is independent and identically distributed.\n",
        "\n",
        "An example of non i.i.d. sampling is SRSWOR. In this case, the draws are no longer independent, because selecting one unit changes the probabilities of selecting the remaining units. As a result, the observations are dependent, and the i.i.d. assumption does not hold.\n",
        "\n"
      ],
      "metadata": {
        "id": "rQRgCUxxeS5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Different Perspectives of i.i.d. Sampling**\n",
        "\n",
        "It is important to note that finite-population sampling and i.i.d. sampling are not fundamentally different. They simply represent different perspectives. Consider the example of estimating the average height of Zog citizens given a SRSWR sample:\n",
        "\n",
        "- Finite-Population Perspective: Heights are viewed as a sample drawn from the population of all people in Zog. The goal is to estimate the population mean of height.\n",
        "\n",
        "- Model-Based (i.i.d.) Perspective: Heights of individuals in both the Zog population and the sample are considered realisations of a random variable (or a data-generating process) $X$. The goal is to estimate the $X$ and study the distribution of heights through this probabilistic model."
      ],
      "metadata": {
        "id": "eLf4Tkjyfdmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sampling Distribution**\n",
        "\n",
        "When we collect data as a sample of size $n$ from a population $X$, we can then calculate some sample statistics as an estimate of population-level characteristics or parameters. But because these statistics are functions of random variables, **the resulting statistics are also random variables** and are thus are subject to interpretation via probabilistic inference via their sampling distribution.\n",
        "\n",
        "The sampling distribution of a statistic describes how the statistic varies across repeated samples from the same population. It allows us to evaluate statistical methods (like probability sampling methods) and forms the basis for statistical inference.\n",
        "\n",
        "For non-probability sampling methods, a formal sampling distribution does not exist (as the probability of selecting each observation is not known). Consequently, it is not possible to quantify or correct for bias in the estimates.\n",
        "\n"
      ],
      "metadata": {
        "id": "3JJaYAaZpUWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Deriving Sampling Distribution**\n",
        "\n",
        "The sampling distribution theoretically arises when taking repeated random samples of size $n$ from a population. Typically is derived in one of three ways:\n",
        "\n",
        "- Mathematical derivation directly from the probability distribution of the data and the laws of probability.\n",
        "\n",
        "- Simulation-based methods where the sampling distribution can be approximated by taking repeated samples and making an empirical estimate of the probability distribution.\n",
        "\n",
        "- Asymptotic approximation, where under certain theorems and properties of the sample statistics, as $n$ increases, it is reasonable to assume properties of the sampling distribution.\n",
        "\n",
        "In this workshop, we focus mostly on simulation-based methods and asymptotic approximation of the sampling distribution of the sample mean via the central limit theorem.\n"
      ],
      "metadata": {
        "id": "xZq74mU6jk01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Asymptotic Sampling Distribution of the Sample Mean**\n",
        "\n",
        "\n",
        "The **Central Limit Theorem (CLT)** is one of the most important theorems in statistics. It provides a powerful tool for making inferences about the **population mean** or expected value based on sample statistics.  \n",
        "\n",
        "Formally, for i.i.d. sample of size $n$ drawn from any probability distribution with mean $\\mu$ and variance $\\sigma^2$:  \n",
        "\n",
        "$$\n",
        "\\displaystyle \\frac{\\sqrt{n} (\\bar{x} - \\mu)}{\\sigma} \\;\\;\\; \\stackrel{d}{\\longrightarrow} \\;\\; N(0,1),\n",
        "$$  \n",
        "\n",
        "In simpler terms, as $n$ increases, the **sampling distribution of the sample mean** $\\bar{x}$ converges to a **normal distribution** with mean $\\mu$ and variance $\\sigma^2 / n$.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HXMvrABTjnSI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In practice, when the sample size $n$ is sufficiently large, the **CLT approximation** can be applied.\n",
        "$$\n",
        "\\displaystyle \\bar{x} \\approx \\mathcal{N}(\\mu, \\sigma^2/n).\n",
        "$$  \n",
        "\n",
        "\n",
        "\n",
        "How large $n$ needs to be depends on various factors, such as the **skewness** of the population distribution. A common rule of thumb is that if\n",
        "\n",
        "$$\n",
        "n > 25 \\times (\\text{skewness})^2,\n",
        "$$\n",
        "\n",
        "the normal approximation is reasonable (see [Sampling Techniques, 3rd Edition | Wiley](https://www.wiley.com/en-us/Sampling+Techniques%2C+3rd+Edition-p-9780471162407). Here, the **skewness** can be estimated from the data.\n",
        "\n",
        "Another common rule of thumb is that if\n",
        "\n",
        "$$\n",
        "n > 30,\n",
        "$$\n",
        "\n",
        "the normal approximation is reasonable. However, it is less precise when data are heavily skewed."
      ],
      "metadata": {
        "id": "XC9pCax3utRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Examples**"
      ],
      "metadata": {
        "id": "Dssw5MW3jtGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **How Large Should `n` Be?**"
      ],
      "metadata": {
        "id": "duoHMYejvLoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will visually demonstrate the CLT for populations with different skewness levels. For each example, we will draw 10,000 samples, and compute the sample mean for each, forming the estimated sampling distribution of the sample mean."
      ],
      "metadata": {
        "id": "tR2HFfs8nLmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Squared standard Gaussian**:"
      ],
      "metadata": {
        "id": "uxN7Ou8YnDqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(1)\n",
        "\n",
        "x = rnorm(10^5)^2 #Draw random sample of size 10^5 from N(0,1)^2\n",
        "print(paste0(\"skewness(x)^2*25 = \", skewness(x)^2*25))\n",
        "x %>% hist(main = \"Histogram of a i.i.d. sample from N(0,1)^2\")"
      ],
      "metadata": {
        "id": "ROy26gHym_lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This suggests that we need a sample size of at least `195`"
      ],
      "metadata": {
        "id": "cy9_DhwTpbmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(1)\n",
        "\n",
        "smpl_mean = numeric(10^4)\n",
        "\n",
        "for(i in 1:10^4){\n",
        "  x = rnorm(10)^2\n",
        "  smpl_mean[i] = mean(x)\n",
        "}\n",
        "smpl_mean %>% hist(breaks = 15, main = \"Estimated sampling distribution of sample mean (n = 10)\")\n",
        "\n",
        "qqnorm(smpl_mean)\n",
        "qqline(smpl_mean)"
      ],
      "metadata": {
        "id": "maeazRb8qfYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(1)\n",
        "\n",
        "smpl_mean = numeric(10^4)\n",
        "\n",
        "for(i in 1:10^4){\n",
        "  x = rnorm(30)^2\n",
        "  smpl_mean[i] = mean(x)\n",
        "}\n",
        "smpl_mean %>% hist(breaks = 15, main = \"Estimated sampling distribution of sample mean (n = 30)\")\n",
        "\n",
        "qqnorm(smpl_mean)\n",
        "qqline(smpl_mean)"
      ],
      "metadata": {
        "id": "DILitqMiqFVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(1)\n",
        "\n",
        "smpl_mean = numeric(10^4)\n",
        "\n",
        "for(i in 1:10^4){\n",
        "  x = rnorm(175)^2\n",
        "  smpl_mean[i] = mean(x)\n",
        "}\n",
        "smpl_mean %>% hist(breaks = 15, main = \"Estimated sampling distribution of sample mean (n = 195)\")\n",
        "qqnorm(smpl_mean)\n",
        "qqline(smpl_mean)"
      ],
      "metadata": {
        "id": "kobYhqsZruPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Poisson(3)**"
      ],
      "metadata": {
        "id": "J6m9Fqnaszin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(1)\n",
        "\n",
        "x = rpois(10^5, 3)\n",
        "print(paste0(\"skewness(x)^2*25 = \", skewness(x)^2*25))\n",
        "x %>% hist(breaks = 15, main = \"Histogram of a i.i.d. sample from Pois(3)\")"
      ],
      "metadata": {
        "id": "5pk_8GQesyux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This suggests that we need a sample size of 8 for the CLT to hold."
      ],
      "metadata": {
        "id": "k1kv3QYftDc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(1)\n",
        "\n",
        "smpl_mean = numeric(10^4)\n",
        "\n",
        "for(i in 1:10^4){\n",
        "  x = rpois(8, 3)\n",
        "  smpl_mean[i] = mean(x)\n",
        "}\n",
        "smpl_mean %>% hist(breaks = 15, main = \"Estimated sampling distribution of sample mean (n = 8)\")\n",
        "qqnorm(smpl_mean)\n",
        "qqline(smpl_mean)"
      ],
      "metadata": {
        "id": "ksHMhTB2tGWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Poisson(10)**"
      ],
      "metadata": {
        "id": "xWTNIKiHnJnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(1)\n",
        "\n",
        "x = rpois(10^4, 10)\n",
        "print(paste0(\"skewness(x)^2*25 = \", skewness(x)^2*25))\n",
        "x %>% hist(breaks = 15,main = \"Histogram of a i.i.d. sample from Pois(10)\")\n"
      ],
      "metadata": {
        "id": "JAV9jRFIr_G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This suggests that we only need a sample size of 3 for the CLT to hold!!!"
      ],
      "metadata": {
        "id": "EoWELCtVsQJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(1)\n",
        "\n",
        "smpl_mean = numeric(1000)\n",
        "\n",
        "for(i in 1:1000){\n",
        "  x = rpois(3, 10)\n",
        "  smpl_mean[i] = mean(x)\n",
        "}\n",
        "smpl_mean %>% hist(breaks = 15, main = \"Estimated sampling distribution of sample mean (n = 3)\")\n",
        "qqnorm(smpl_mean)\n",
        "qqline(smpl_mean)"
      ],
      "metadata": {
        "id": "pOx0qmtIsZmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is obvious that if the true data-generating process is Gaussian then we only need a sample size of 1 for the CLT to hold (since the average of an iid Gaussian random sample is still Gaussian!)."
      ],
      "metadata": {
        "id": "7Jrq8TLQslgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(1)\n",
        "\n",
        "x = rnorm(10^5)\n",
        "print(paste0(\"skewness(x)^2*25 = \", skewness(x)^2*25))\n",
        "x %>% hist(breaks = 15, main = \"Histogram of a i.i.d. sample from standard Gaussian\")"
      ],
      "metadata": {
        "id": "vpF-QncmuYSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Estimating the Probability of $a < \\bar{x} < b$**\n",
        "\n",
        "A beverage plant calibrates a bottling machine to fill 33 cL bottles, but there is some variability in the process, and from time to time, the machine needs adjustment. Every hour, an employee takes a sample of ten bottles and measures the amount of beverage in each one to monitor the machine. Prior testing shows that the volume of each bottle has a mean of 33 cL and a variance of 0.6 cL. What is the (approximate) probability of observing a sample mean of $\\bar{x}\\leq 32.7$ cL based on a sample of \\(n=10\\) bottles?\n",
        "\n"
      ],
      "metadata": {
        "id": "1EjOOoY0uigQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The sampling distribution of the sample mean $\\bar{x}$ is  \n",
        "\n",
        "$$\n",
        "\\displaystyle\n",
        "\\bar{x} \\sim N\\big(\\mu, \\sigma^2/n\\big) \\sim N(33, 0.6/10).\n",
        "$$\n",
        "\n",
        "So $\\Pr(\\bar{x} \\le 32.7)$ can be found using the standard normal distribution:  \n",
        "\n",
        "$$\n",
        "\\displaystyle\n",
        "\\begin{aligned}\n",
        "\\Pr(\\bar{x} \\le 32.7)\n",
        "&= Pr\\Bigg(\\frac{\\bar{x}-\\mu}{\\sigma/\\sqrt{n}} \\le \\frac{32.7-33}{\\sqrt{0.6/10}}\\Bigg) \\\\\n",
        "&= \\Pr(Z \\le -1.22) \\\\\n",
        "&\\approx 0.11.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "This probability can be obtained from standard normal tables or using the `pnorm()` function in R.\n"
      ],
      "metadata": {
        "id": "5DNxDEmpwGCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pnorm(32.7, mean = 33, sd = sqrt(0.6/10))\n",
        "pnorm(-1.22)"
      ],
      "metadata": {
        "id": "LpXFvPls0F9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Asymptotic Sampling Distribution of Sample Proportion**"
      ],
      "metadata": {
        "id": "iDN2T_lywmRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample proportion is a special case of the **sample mean** (for binary variables), so the **CLT** can also be applied to the sample proportion when the sample size $n$ is sufficiently large.\n",
        "\n",
        "For a sample of size $n$, let $x$ be the number of members in the sample who have a trait of interest. The **sample proportion** is  \n",
        "\n",
        "$$\n",
        "\\displaystyle \\hat{p} = \\frac{x}{n}.\n",
        "$$  \n",
        "\n",
        "If we assume that $x$ follows a **binomial distribution** with probability $p$ and size $n$, then  \n",
        "\n",
        "$$\n",
        "\\displaystyle E(x) = np, \\quad \\text{SD}(x) = \\sqrt{np(1-p)}.\n",
        "$$\n",
        "\n",
        "From the properties of expectation and variance, the estimator $\\hat{p}$ has  \n",
        "\n",
        "$$\n",
        "\\displaystyle E(\\hat{p}) = p.\n",
        "$$  \n",
        "\n",
        "and **standard error**  \n",
        "\n",
        "$$\n",
        "\\displaystyle \\text{SE}(\\hat{p}) = \\sqrt{\\frac{p(1-p)}{n}}.\n",
        "$$\n"
      ],
      "metadata": {
        "id": "0JYgzq7ZxdKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If $n$ is sufficiently large,\n",
        "\n",
        "$$\n",
        "\\displaystyle \\hat{p} \\approx \\mathcal{N}\\Big(p, \\frac{p(1-p)}{n}\\Big).\n",
        "$$  "
      ],
      "metadata": {
        "id": "-ELlBHKZynDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A standard rule of thumb to determine whether or not $n$ is sufficiently large is if $np>5$ and $n(1-p)>5$, then we can assume that the sampling distribution of $\\hat{p}$ is approximately Gaussian."
      ],
      "metadata": {
        "id": "UfpRZTpky498"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Example**\n",
        "\n",
        "Suppose a population has a proportion $p = 0.6$ of people who prefer coffee over tea. We draw an i.i.d. random sample of size $n = 100$ from the population. Let $\\hat{p}$ denote the sample proportion.  \n",
        "\n",
        "By the CLT, for sufficiently large $n$, the sampling distribution of $\\hat{p}$ is approximately normal:  \n",
        "\n",
        "$$\n",
        "\\displaystyle \\hat{p} \\sim N\\Big(p, \\frac{p(1-p)}{n}\\Big) = N\\Big(0.6, \\frac{0.6 \\times 0.4}{100}\\Big)\n",
        "$$\n",
        "\n",
        "We want to compute (approximately) the probability that the sample proportion is between 0.55 and 0.65:  \n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\displaystyle P(0.55 \\le \\hat{p} \\le 0.65) &= P\\left(\\frac{0.55-0.6}{\\sqrt{0.6 \\cdot 0.4 / 100}} \\le Z \\le \\frac{0.65-0.6}{\\sqrt{0.6 \\cdot 0.4 / 100}}\\right) \\\\\n",
        "&= P(-1.021 \\le Z \\le 1.021) \\\\\n",
        "&\\approx 0.692\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "\n",
        "We can compute this in **R** using `pnorm()`:\n"
      ],
      "metadata": {
        "id": "3GGdJ1xhwmtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = 0.6\n",
        "n = 100\n",
        "se = sqrt(p*(1-p)/n)\n",
        "\n",
        "pnorm(0.65, mean = p, sd = se) - pnorm(0.55, mean = p, sd = se)\n",
        "pnorm(-1.021) - pnorm(1.021)"
      ],
      "metadata": {
        "id": "XxcspydU0Xoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Workshop Questions**\n"
      ],
      "metadata": {
        "id": "uO9c9T2QAGqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 1**\n",
        "\n",
        "The planet Zog wants to know the average height of its inhabitants. Since it is usually impractical to survey the entire population, a sample of 25 individuals is taken from the `planetZog` dataset. You, however, have access to the full population data, which allows you to compare the performance of different sampling methods.\n",
        "\n",
        "You are required to complete the following tasks:\n",
        "- Compute the mean and standard deviation of height of citizens within each district. Comment on the output.\n",
        "- Perform SRSWOR and StRS with proportional allocation ($n = 25$) to estimate the average population height.\n",
        "- Repeat each sampling procedure 100 times.\n",
        "- Compare the sampling distributions of the sample mean for the two methods using an appropriate graphical method.\n",
        "\n",
        "**Hint**:\n",
        "- Create empty vectors to save estimated sample means.\n",
        "- Use `pull()` to extract average height from the output of `summarise()`."
      ],
      "metadata": {
        "id": "D7dmSJpy5-c4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "planetZog %>%\n",
        "  group_by(District) %>%\n",
        "  summarise(avgHeight = mean(Height),\n",
        "            sdHeight = sd(Height))"
      ],
      "metadata": {
        "id": "rAr_GUDj6S_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe within-group homogeneity and between-group heterogeneity. StRS is expected to be more efficient than SRSWOR."
      ],
      "metadata": {
        "id": "CubvQ-CpLGjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(123)\n",
        "SRSWOR = StRS = numeric(100)\n",
        "N = nrow(planetZog)\n",
        "smplSize = 25\n",
        "for(i in 1:100){\n",
        "\n",
        "  #Perform SRSWOR\n",
        "\n",
        "  planetZog %>%\n",
        "    slice_sample(n = smplSize) %>%\n",
        "    summarise(popAvgHeight = mean(Height))  %>%\n",
        "    pull(popAvgHeight) -> SRSWOR[i]\n",
        "\n",
        "  #Perform StRS\n",
        "  planetZog %>%\n",
        "    group_by(District) %>%\n",
        "    mutate(Nh = n()) %>% #stratum sizes\n",
        "    sample_n(size = ceiling(smplSize*n()/N)) %>%\n",
        "    summarise(stratumAvgHeight = mean(Height),\n",
        "              Nh = Nh[1]) %>%\n",
        "    ungroup() %>%\n",
        "    summarise(popAvgHeight = sum(stratumAvgHeight*Nh)/sum(Nh)) %>%\n",
        "    pull(popAvgHeight) -> StRS[i]\n",
        "\n",
        "}\n",
        "\n",
        "boxplot(cbind(SRSWOR = SRSWOR, StRS = StRS), main = \"Average height of Zog citizens (cm)\")"
      ],
      "metadata": {
        "id": "BqBdFRFCLJ4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, the estimator based on StRS exhibits substantially lower variance than the SRS estimator"
      ],
      "metadata": {
        "id": "b9oQEZuPLNTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 2**\n",
        "\n",
        "An automotive battery producer makes a certain model of battery with an average life of 1110 days with a standard deviation of 80 days. Given a sample of size $n = 40$, find the probability that:\n",
        "\n",
        "- The average battery for the sample is between 1100 and 1110 days."
      ],
      "metadata": {
        "id": "D0fYT6WZAOfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assuming that $n = 40$ is sufficiently large for the CLT to hold,\n",
        "\n",
        "$$\\begin{align}\n",
        "\\bar{x} &\\approx \\mathcal(1100, 80^2)\\\\\n",
        "n&= 40\\\\\n",
        "\\mathbb{E}(\\bar{x}) &= 1100 \\\\\n",
        "\\mathbb{V}(\\bar{x}) &= \\frac{80^2}{40} = 160\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "\n",
        "We want to calculate the probability:  \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\Pr(1100 < \\bar{x} < 1110)\n",
        "&= \\Pr\\left( \\frac{1100 - \\mu}{\\sigma/\\sqrt{n}} < \\frac{\\bar{x} - \\mu}{\\sigma/\\sqrt{n}} < \\frac{1110 - \\mu}{\\sigma/\\sqrt{n}} \\right) \\\\\n",
        "&= \\Pr\\left( \\frac{1100 - 1110}{80/\\sqrt{40}} < Z < \\frac{1110 - 1110}{80/\\sqrt{40}} \\right) \\\\\n",
        "&= \\Pr(0 < Z < 0.7905694) \\\\\n",
        "&= \\Pr(Z < 0.7905694) - Pr(Z < 0) \\\\\n",
        "&\\approx 0.285\n",
        "\\end{aligned}\n",
        "$$"
      ],
      "metadata": {
        "id": "HpSqquyPLXKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Z <- 10/(80/sqrt(40))\n",
        "pnorm(Z)-pnorm(0)\n",
        "# > [1] 0.2854023"
      ],
      "metadata": {
        "id": "zkjwogkE2xzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The average battery life for the sample is greater than 1120 days"
      ],
      "metadata": {
        "id": "K_q-vNQy4acf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We want to calculate the probability:  \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\Pr(\\bar{x} > 1120)\n",
        "&= \\Pr\\left(\\frac{\\bar{x} - \\mu}{\\sigma/\\sqrt{n}} > \\frac{1120 - \\mu}{\\sigma/\\sqrt{n}} \\right) \\\\\n",
        "&= \\Pr\\left(Z > 1.581139 \\right) \\\\\n",
        "&\\approx 0.057\n",
        "\\end{aligned}\n",
        "$$"
      ],
      "metadata": {
        "id": "CbJ6ff97LfwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Z <- (1120-1100)/(80/sqrt(40))\n",
        "pnorm(Z, lower.tail = FALSE)"
      ],
      "metadata": {
        "id": "5wzQYQI04j2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 3**\n",
        "\n",
        "\n",
        "A factory produces light bulbs, and historically, 5% of them are defective. To monitor quality, an inspector randomly selects 150 bulbs each day. Let $\\hat{p}$ be the sample proportion of defective bulbs in a daily sample.  \n"
      ],
      "metadata": {
        "id": "pZrQPv2nw_SN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use the CLT, approximate the sampling distribution of $\\hat{p}$.  \n"
      ],
      "metadata": {
        "id": "iJo5vUDDAMZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By the CLT, for sufficiently large $n$, the sampling distribution of $\\hat{p}$ is approximately normal:  \n",
        "\n",
        "$$\n",
        "\\hat{p} \\sim N\\Big(p, \\frac{p(1-p)}{n}\\Big) = N\\Big(0.05, \\frac{0.05 \\times 0.95}{150}\\Big)\n",
        "$$"
      ],
      "metadata": {
        "id": "kV-rOkDZLmx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Explain why the CLT approximation is reasonable in this context."
      ],
      "metadata": {
        "id": "9etaZtMAARjU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we have\n",
        "\n",
        "$$\n",
        "np = 150\\times0.05 = 7.5 > 5,\n",
        "$$\n",
        "and\n",
        "$$\n",
        "n(1-p) = 150\\times0.95 = 142.5 > 5,\n",
        "$$\n",
        "the CLT approximation is adequate."
      ],
      "metadata": {
        "id": "X3wb_MQJLrf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Compute the probability that the daily sample contains more than 10% defective bulbs.  \n"
      ],
      "metadata": {
        "id": "Eof_oh0iAOvE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to compute the probability that the sample proportion exceeds 10%:  \n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "P(\\hat{p} > 0.10) &= P\\left(\\frac{0.10-0.05}{\\sqrt{0.05 \\cdot 0.95 / 150}} \\le Z\\right) \\\\\n",
        "&= P(Z > 2.81) \\\\\n",
        "&\\approx 0.0025\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "We can compute this in **R** using `pnorm()`:  "
      ],
      "metadata": {
        "id": "hIb_wGqjLweP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = 0.05\n",
        "n = 150\n",
        "x = 0.10\n",
        "\n",
        "se = sqrt(p * (1 - p) / n)\n",
        "pnorm(x, mean = p, sd = se, lower.tail = F)\n",
        "[1] 0.002478943"
      ],
      "metadata": {
        "id": "pQIHbqunBSM-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}