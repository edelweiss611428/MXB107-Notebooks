{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Week 2: Numerical Data Summaries**\n",
        "\n",
        "```\n",
        ".------------------------------------.\n",
        "|   __  ____  ______  _  ___ _____   |\n",
        "|  |  \\/  \\ \\/ / __ )/ |/ _ \\___  |  |\n",
        "|  | |\\/| |\\  /|  _ \\| | | | | / /   |\n",
        "|  | |  | |/  \\| |_) | | |_| |/ /    |\n",
        "|  |_|  |_/_/\\_\\____/|_|\\___//_/     |\n",
        "'------------------------------------'\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "ZtpJJ8BSHOaK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This week, we will explore basic summary statistics for numerical data and demonstrate how to compute them in R. If you are not familiar with R programming, please take some time to review [Week 0](https://colab.research.google.com/github/edelweiss611428/MXB107-Notebooks/blob/main/notebooks/Week_0.ipynb) and [Week 1](https://colab.research.google.com/github/edelweiss611428/MXB107-Notebooks/blob/main/notebooks/Week_1.ipynb) content."
      ],
      "metadata": {
        "id": "QWuoIciBrV25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pre-Configurating the Notebook**"
      ],
      "metadata": {
        "id": "SpK9XLxlHOcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Switching to the R Kernel on Colab**\n",
        "\n",
        "By default, Google Colab uses Python as its programming language. To use R instead, you’ll need to manually switch the kernel by going to **Runtime > Change runtime type**, and selecting R as the kernel. This allows you to run R code in the Colab environment.\n",
        "\n",
        "However, our notebook is already configured to use R by default. Unless something goes wrong, you shouldn’t need to manually change runtime type."
      ],
      "metadata": {
        "id": "4yA6tfrakIOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importing Required Datasets and Packages**\n",
        "**Run the following lines of code**:"
      ],
      "metadata": {
        "id": "VLNikK3CYWIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Do not modify\n",
        "\n",
        "setwd(\"/content\")\n",
        "\n",
        "# Remove `MXB107-Notebooks` if exists,\n",
        "if (dir.exists(\"MXB107-Notebooks\")) {\n",
        "  system(\"rm -rf MXB107-Notebooks\")\n",
        "}\n",
        "\n",
        "# Fork the repository\n",
        "system(\"git clone https://github.com/edelweiss611428/MXB107-Notebooks.git\")\n",
        "\n",
        "# Change working directory to \"MXB107-Notebooks\"\n",
        "setwd(\"MXB107-Notebooks\")\n",
        "\n",
        "#\n",
        "invisible(source(\"R/preConfigurated.R\"))"
      ],
      "metadata": {
        "id": "tYGemispahiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do not modify the following**"
      ],
      "metadata": {
        "id": "o_XFVhdp1GrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (!require(\"testthat\")) install.packages(\"testthat\"); library(\"testthat\")\n",
        "\n",
        "test_that(\"Test if all packages have been loaded\", {\n",
        "\n",
        "  expect_true(all(c(\"ggplot2\", \"tidyr\", \"dplyr\", \"stringr\", \"magrittr\", \"IRdisplay\", \"png\") %in% loadedNamespaces()))\n",
        "\n",
        "})\n",
        "\n",
        "test_that(\"Test if all utility functions have been loaded\", {\n",
        "  expect_true(exists(\"skewness\"))\n",
        "  expect_true(exists(\"kurtosis\"))\n",
        "  expect_true(exists(\"Mode\"))\n",
        "  expect_true(exists(\"FDbinning\"))\n",
        "  expect_true(exists(\"ModeBinMidpoint\"))\n",
        "  expect_true(exists(\"empiricalRuleGaussian\"))\n",
        "  expect_true(exists(\"chebyshevRule\"))\n",
        "  expect_true(exists(\"rangeBasedSD\"))\n",
        "  expect_true(exists(\"IQRBasedSD\"))\n",
        "  expect_true(exists(\"boxPlotDescribe\"))\n",
        "})"
      ],
      "metadata": {
        "id": "6lru0NFK011G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Classification of Data**\n"
      ],
      "metadata": {
        "id": "GZJWyX_QM70-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a diagram of data types."
      ],
      "metadata": {
        "id": "mzu2jNwFUgVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svgCode = paste(readLines(\"figures/classif_of_data.svg\", warn = F), collapse = \"\\n\")\n",
        "display_html(svgCode)"
      ],
      "metadata": {
        "id": "RU6Nj403Q91C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you go lower in the diagram, the data types become more specific but also a bit more limited — they carry less detailed information and support fewer types of analysis, and you can do fewer kinds of analysis on them."
      ],
      "metadata": {
        "id": "G-wEq2EaVXKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We’ll focus exclusively on numerical data in this unit. It is by far the most common type encountered in data analysis tasks. Categorical data will be briefly touched on in later workshops."
      ],
      "metadata": {
        "id": "VbToMTck3xkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Statistical Inference**\n",
        "\n",
        "This diagram illustrates the fundamental process in statistics:\n",
        "\n",
        "- We first start with a population, which is the entire set of items, individuals, or events we want to study. (e.g., all QUT students).\n",
        "\n",
        "- Since it is often impractical or impossible to collect data on the entire population, we only draw a random sample from the population. (e.g., randomly select 100 QUT students).\n",
        "\n",
        "- We then analyse the sample data and make statistical inferences (conclusions) about the larger population (e.g., average GPA).\n",
        "\n",
        "This process is the core of statistical inference — using limited data to learn about a much larger group. If we did have access to the whole population, statistical inference would be unnecessary because we would already know all the information."
      ],
      "metadata": {
        "id": "dXy8y8B976nH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svgCode = paste(readLines(\"figures/inference.svg\", warn = F), collapse = \"\\n\")\n",
        "display_html(svgCode)"
      ],
      "metadata": {
        "id": "8mLJr2xqOLOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having introduced the basic concepts of statistical inference, we now focus on the most fundamental tools  — **summary statistics**. These statistics describe important features of the sample data and provide essential information for drawing inferences about the population including:\n",
        "\n",
        "- What is the central or typical value of the data? *(e.g., What is the average GPA of QUT students?)*\n",
        "- How much variability or dispersion exists within the data? *(e.g., How widely do GPAs vary among QUT students?)*\n",
        "- Are there any data points that deviate markedly from the rest? *(e.g., Are there students with unusually low or high GPAs compared to their peers?)*\n",
        "\n",
        "We will call these the three measures of summary statistics, namely:\n",
        "\n",
        "- Measures of central tendency — statistics that describe the center or typical value of the data (e.g., mean, median, mode).\n",
        "- Measures of variability — statistics that describe the spread or dispersion of the data (e.g., variance, standard deviation, interquartile range).\n",
        "- Measures of shape — statistics that describe the distributional form of the data (e.g., skewness, kurtosis)."
      ],
      "metadata": {
        "id": "NHQGCh1u8Cyz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Measures of Central Tendency**"
      ],
      "metadata": {
        "id": "U_ePA59nkztM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dataset**\n",
        "\n",
        "We will load a simulated dataset with 4 variables, each having 100 observations (with/without outliers). The non-outlier observations are generated from a standard Gaussian (also referred to as \"normal\" or \"bell-shaped\") distribution. The \"standard\" means that the mean of the distribution is set to 0 and the variance is set to 1 (so the standard deviation is also 1). However, the magnitude of the outlying values increases across the variables. Here, the outliers are positive."
      ],
      "metadata": {
        "id": "qm3Wjdwyu6Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = read.csv(\"./datasets/centraltendency\")"
      ],
      "metadata": {
        "id": "2MREm1Vk-_2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will use boxplots to visualise the data and get an overview of its distribution and potential outliers. We will return later to explain in detail what the various components of a boxplot represent."
      ],
      "metadata": {
        "id": "iDWJTfvL_X4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boxplot(X, main = \"Boxplots of several Gaussian datasets with/without outliers\")"
      ],
      "metadata": {
        "id": "WJk_M7cg_baf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The majority of the data in each variable lie around 0. However, we observe that the magnitude of the outliers increases across variables, from 0 to 100. We expect a *good* measure of central tendency to reflect the typical values accurately even in the presence of these outliers."
      ],
      "metadata": {
        "id": "a9gS5qAp-_UT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that `ggplot2` is great, but not always necessary. In many cases, base R plots can achieve much of the same functionality — they might just look a bit \"uglier.\" We will explore how to create boxplots in `ggplot2` in later sections."
      ],
      "metadata": {
        "id": "FrfAxXcFkm45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Arithmetic Mean**\n",
        "\n",
        "\n",
        "The arithmetic mean is the sum of all data values divided by the number of values. It represents the \"average\" value of a dataset and is a common measure of central tendency.\n",
        "\n",
        "$$\n",
        "\\text{Mean}(x_1, \\dots, x_n) \\equiv \\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i,\n",
        "$$\n",
        "where $\\{x_i\\}_{i=1}^n$ denotes the sample of $n$ observations.\n",
        "\n",
        "#### **Properties of Arithmetic Mean**  \n",
        "- In the absence of outliers, the arithmetic mean is an efficient and unbiased estimator of the population mean (on average it matches the true population mean); its accuracy improves as the sample size increases.\n",
        "- Unfortunately, the arithmetic mean is sensitive to outliers and extreme values — these can substantially affect its value.\n",
        "- It is most appropriate for numeric data without significant skewness or extreme outliers.\n",
        "\n",
        "What is skewness? We will talk about it later."
      ],
      "metadata": {
        "id": "OUtX3rEuAC9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **R Examples**\n",
        "\n",
        "In R, the arithmetic mean can be calculated using the built-in `mean()` function. This function takes a numeric vector as input and returns the average of its elements."
      ],
      "metadata": {
        "id": "731dl3o-RB7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean(X$G0)\n",
        "mean(X$G0_oult25)\n",
        "mean(X$G0_oult50)\n",
        "mean(X$G0_oult100)"
      ],
      "metadata": {
        "id": "Jussxwd-BHaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use the `colMeans()` function to compute arithmetic means of all columns in the data frame `X`. This is generally more computationally efficient."
      ],
      "metadata": {
        "id": "A2oa14MjBRMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(colMeans(X))"
      ],
      "metadata": {
        "id": "095UIq33Bdj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that the arithmetic mean increases as the magnitude of the outliers increases. This behavior is undesirable when measuring central tendency, as it reflects a lack of robustness. Ideally, we seek a measure that is less affected by extreme values."
      ],
      "metadata": {
        "id": "EcKA0BdDB-zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boxplot(X, main = \"Boxplots of several Gaussian datasets with/without outliers\")\n",
        "\n",
        "cMeans = colMeans(X)\n",
        "points(1:4, cMeans, pch = 19, col = \"red\", cex = 1.25)\n",
        "# Add legend\n",
        "legend(\"topleft\", legend = c(\"Mean\"),\n",
        "       cex = c(1.25), col = c(\"red\"), bty = \"n\",\n",
        "       pch = c(19))"
      ],
      "metadata": {
        "id": "SbglkMgQDM5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Median**\n",
        "\n",
        "The **median** is the middle value of an ordered dataset. It divides the data into two equal halves — 50% of the observations lie below the median, and 50% lie above.\n",
        "\n",
        "- For a dataset of size $n$, sorted in ascending order:\n",
        "  - If $n$is **odd**, the median is the value at position $\\frac{n + 1}{2}$.\n",
        "  - If $n$ is **even**, the median is the average of the two middle values at positions $\\frac{n}{2}$ and $\\frac{n}{2} + 1$.\n",
        "\n",
        "$$\n",
        "\\text{Median}(x_1, \\dots, x_n) =\n",
        "\\begin{cases}\n",
        "x_{\\big(\\frac{n + 1}{2}\\big)}, & \\text{if } n \\text{ is odd}, \\\\\\\\\n",
        "\\frac{1}{2} \\left(x_{\\big(\\frac{n}{2}\\big)} + x_{\\big(\\frac{n}{2} + 1\\big)} \\right), & \\text{if } n \\text{ is even},\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "where $x_{(1)}, x_{(2)}, \\dots, x_{(n)}$ denotes the sorted sample.\n",
        "\n",
        "####  **Properties of the Median**\n",
        "- The median is **robust to outliers**.\n",
        "- It is a more **reliable measure of central tendency** than the mean for skewed distributions or data with outliers.\n",
        "- Suitable for both **ordinal** and **continuous** data.\n",
        "\n",
        "To compute the median in R, use the `median()` function. It takes a numeric vector and returns the sample median.\n"
      ],
      "metadata": {
        "id": "oRG13tdyESnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "median(X$G0)\n",
        "median(X$G0_oult25)\n",
        "median(X$G0_oult50)\n",
        "median(X$G0_oult100)"
      ],
      "metadata": {
        "id": "2Yp7J0KPL8Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **R Examples**\n",
        "\n",
        "Unlike mean, there is no  `colMedians()` function to compute the medians of all columns in the data frame `X`. However, we can use `apply()` function to repeatedly apply the `median()` function to each of the column in `X`. This is generally more computationally efficient."
      ],
      "metadata": {
        "id": "QD0m57WrMIzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(apply(X, MARGIN = 2, median)) #MARGIN = 2: apply `median()` to all columns"
      ],
      "metadata": {
        "id": "puihHcvmMVXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The median does not increase as the magnitute of outlying values increases, which is desirable."
      ],
      "metadata": {
        "id": "tQn5sX5iMtfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boxplot(X, main = \"Boxplots of several Gaussian datasets with/without outliers\")\n",
        "\n",
        "cMeans = colMeans(X)\n",
        "cMedians = apply(X, 2, median)\n",
        "\n",
        "points(1:4, cMeans, pch = 19, col = \"red\", cex = 1.25)\n",
        "points(1:4, cMedians, pch = 15, col = \"blue\", cex = 1.25)\n",
        "\n",
        "# Add legend\n",
        "legend(\"topleft\", legend = c(\"Mean\", \"Median\"),\n",
        "       cex = rep(1.25, 2), col = c(\"red\", \"blue\"), bty = \"n\",\n",
        "       pch = c(19,15))"
      ],
      "metadata": {
        "id": "V7l_APPVFURk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> While the mean is the most commonly understood measure of average, median measures are most representative of an \"average\" employee’s earnings as earnings data has a positively skewed distribution. The mean is higher than the median value because of a small number of people with very high earnings.  See [Australian Bureau of Statistics – Average Earnings Guide](https://www.abs.gov.au/statistics/understanding-statistics/guide-labour-statistics/earnings-guide/average-earnings-guide) for more details.\n",
        "\n"
      ],
      "metadata": {
        "id": "jQ6cdj-RNTBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The figure below is from [Australian Bureau of Statistics – Average Earnings Guide](https://www.abs.gov.au/statistics/understanding-statistics/guide-labour-statistics/earnings-guide/average-earnings-guide), showing the median and average weekly earnings of employees in Australian."
      ],
      "metadata": {
        "id": "2ldExNuTQD05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img = readPNG(\"figures/abs_earning.png\")\n",
        "grid.newpage()\n",
        "vp = viewport(width = 1.25, height = 1.25)\n",
        "pushViewport(vp)\n",
        "grid.raster(img)\n",
        "popViewport()"
      ],
      "metadata": {
        "id": "DaEiKOx3O55n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Mode**\n",
        "\n",
        "The **mode** is the value(s) that occur most frequently in a dataset. It represents the *most common* observation(s).\n",
        "\n",
        "- For a dataset $x_1, x_2, \\dots, x_n$, the mode is the value $m$ such that the count of $m$ is greater than or equal to the count of any other value.\n",
        "\n",
        "Formally, if $f(x)$ is the frequency of value $x$:\n",
        "\n",
        "$$\n",
        "\\text{Mode} = \\arg\\max_{x} f(x).\n",
        "$$\n",
        "\n",
        "- A dataset can be:\n",
        "  - **Unimodal**: one unique mode,\n",
        "  - **Multimodal**: multiple modes,\n",
        "  - **No mode**: if all values are unique (appear only once).\n",
        "\n",
        "####  **Properties of the Mode**\n",
        "- The mode is the only measure of central tendency applicable to **nominal categorical** data.\n",
        "- For continuous numeric data **without binning or grouping**, the mode is often **not meaningful**, because the probability of observing the exact same value twice in a continuous distribution is effectively **zero**. Essentially, there is **no mode**. However, we will see later in the unit how we can estimate the mode by estimating the distribution of the underlying data.\n",
        "- It is sensitive to the level of data discretisation (binning) but less sensitive to outliers than the sample mean (if data are well-binned).\n"
      ],
      "metadata": {
        "id": "xy3-7TKFQexj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  **R Examples**\n",
        "\n",
        "There is no built-in `mode()` function in R. In R, `mode()` is more or less similar to `typeof()`, which tells us the data type of an R object. We, however, have prepared some useful functions, which help you bin the data and then compute the mode(s).\n",
        "\n",
        "- `Mode()`: Computes the mode(s) given a numeric vector.\n",
        "- `FDbinning()`: Bins the data into intervals according to the Freedman–Diaconis (FD) method, which is quite robust to outliers.\n",
        "\n",
        "We first apply the `Mode()` function to the raw data in column `G0` in the dataset to compute the modes."
      ],
      "metadata": {
        "id": "TtMrXF1fSUvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modeRawG0 = Mode(X$G0)\n",
        "print(modeRawG0)"
      ],
      "metadata": {
        "id": "nemNCOdoQeOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It returns the vector of mode values, whose length is equal to the number of observations. As every observation is a mode, there is essentially no mode."
      ],
      "metadata": {
        "id": "rW24Apu-TjiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "length(modeRawG0)"
      ],
      "metadata": {
        "id": "cZ8y2kAYTeae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the `FDbinning()` function to bin the data into intervals."
      ],
      "metadata": {
        "id": "Z7EXMvnsUDng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binnedG0 = FDbinning(X$G0)\n",
        "print(binnedG0)\n",
        "length(binnedG0)"
      ],
      "metadata": {
        "id": "hkgFOQHZUgGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we can compute the most frequent interval using the `Mode()` function."
      ],
      "metadata": {
        "id": "ltk3rd0aUrbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Mode(binnedG0)"
      ],
      "metadata": {
        "id": "MMUJwCRcU21K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercise 1**\n",
        "\n",
        "The most frequent interval in the demonstrated example above is quite close to the central tendency of the data. We are, however, interested in the situations where outliers are present.\n",
        "\n",
        "Compute the mode of the FD-binned data for the other columns in the data frame X. Then, comment on how the most frequent interval(s) changes as the magnitude of the outlying values increases. Is that sensitive to outliers?"
      ],
      "metadata": {
        "id": "nuRP3ITyU9pv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O0kFJ_v4XFyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>▶️ Click to show the solution</summary>\n",
        "\n",
        "```r\n",
        "Mode(FDbinning(X$G0_oult25))\n",
        "Mode(FDbinning(X$G0_oult50))\n",
        "Mode(FDbinning(X$G0_oult100))\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "AiIxJlqFXIxQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercise 2**\n",
        "\n",
        "We have provided a function named `ModeBinMidpoint()`, which computes the mid-point of the most frequent interval. You can think of that as a function like `mean()` and `median()`, which takes a numeric vector and returns a value.\n",
        "\n",
        "Use `apply()` to compute `ModeBinMidpoint` for all columns in the data frame `X` and assign the results to the `cModes` variable by **modifying the code cell below**."
      ],
      "metadata": {
        "id": "pkzggoyLXTvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boxplot(X, main = \"Boxplots of several Gaussian datasets with/without outliers\")\n",
        "\n",
        "cMeans = colMeans(X)\n",
        "cMedians = apply(X, 2, median)\n",
        "cModes = c(-5,-5,-5,-5) #Modify this line of code\n",
        "\n",
        "points(1:4, cMeans, pch = 19, col = \"red\", cex = 1.25)\n",
        "points(1:4, cMedians, pch = 15, col = \"blue\", cex = 1.25)\n",
        "points(1:4, cModes, pch = 15, col = \"green\", cex = 1.25)\n",
        "# Add legend\n",
        "legend(\"topleft\", legend = c(\"Mean\", \"Median\", \"Mode\"),\n",
        "       cex = rep(1.25, 3), col = c(\"red\", \"blue\", \"green\"), bty = \"n\",\n",
        "       pch = c(19,15, 17))"
      ],
      "metadata": {
        "id": "ywLj53oMYSLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>▶️ Click to show the solution</summary>\n",
        "\n",
        "```r\n",
        "boxplot(X, main = \"Boxplots of several Gaussian datasets with/without outliers\")\n",
        "\n",
        "cMeans = colMeans(X)\n",
        "cMedians = apply(X, 2, median)\n",
        "cModes = apply(X,2, ModeBinMidpoint)\n",
        "\n",
        "points(1:4, cMeans, pch = 19, col = \"red\", cex = 1.25)\n",
        "points(1:4, cMedians, pch = 15, col = \"blue\", cex = 1.25)\n",
        "points(1:4, cModes, pch = 15, col = \"green\", cex = 1.25)\n",
        "# Add legend\n",
        "legend(\"topleft\", legend = c(\"Mean\", \"Median\", \"Mode\"),\n",
        "       cex = rep(1.25, 3), col = c(\"red\", \"blue\", \"green\"), bty = \"n\",\n",
        "       pch = c(19,15, 17))\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "8fxNQeleZWDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Measure of Variability**\n",
        "\n",
        "We use the same dataset as in the previous section.\n",
        "\n",
        "### **Sample Variance**\n",
        "\n",
        "Given a sample of observations of size $n$ with sample mean $\\bar{x}$, the sample variance is\n",
        "\n",
        "$$\\text{Variance}(x_1, \\dots, x_n) \\equiv s^2 = \\frac{\\sum_{i=1}^n(x_i-\\bar{x})^2}{n-1}.$$\n",
        "\n",
        "The variance is basically the average of the squared distance between observations and the sample mean, and as such, it has the advantage of being based on all the observations.\n",
        "\n",
        "### **Properties of the Sample Variance**\n",
        "\n",
        "- In the absence of outliers, the sample variance is an efficient and unbiased estimator of the population variance; its accuracy improves as the sample size increases.\n",
        "- Unfortunately, the sample variance is sensitive to outliers since squaring amplifies the effect of extreme values. Also, it uses the sample mean, which is not a robust estimator.\n",
        "- Interpreting the sample variance is difficult as its units are the square of the units for the observations. For example, if $x_i$ is a measurement of time in seconds, then the sample variance $s^2$ is in the units $\\text{seconds}^{2}$. Conceptually it is difficult to understand a squared second in terms of the data.\n"
      ],
      "metadata": {
        "id": "y7IIcNNxZpba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **R Examples**\n",
        "In R, the sample variance can be calculated using the built-in `var()` function. This function takes a numeric vector as input and returns the sample variance."
      ],
      "metadata": {
        "id": "QOalfq0jh6A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "var(X$G0)\n",
        "var(X$G0_oult25)\n",
        "var(X$G0_oult50)\n",
        "var(X$G0_oult100)"
      ],
      "metadata": {
        "id": "UxN6yuBZiG9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no `colVars()` function in R. However, we can use the `apply()` functions to compute column variances.\n"
      ],
      "metadata": {
        "id": "9aFM1WewjcYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(apply(X, 2, var))"
      ],
      "metadata": {
        "id": "EdPXw_Hzjkuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that the variance increases as the magnitude of the outliers increases—at a rate substantially faster than that of the mean. A *robust* estimate of the sample variance should give us a value close to $1$ **as the non-outlying observations had a theoretical variance of 1**."
      ],
      "metadata": {
        "id": "CzuTjc_zifej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outlVals = c(0,25,50,100)\n",
        "meanVals = apply(X,2,mean)\n",
        "varVals = apply(X,2,var)\n",
        "\n",
        "\n",
        "plot(outlVals, varVals, type = \"l\", lty = 4, col = \"black\", xaxt = \"n\")\n",
        "points(outlVals, varVals,pch = 3, col = \"black\")\n",
        "axis(side = 1, at = c(0, 25, 50, 100))\n",
        "\n",
        "lines(outlVals, meanVals, type = \"l\", lty = 2, col = \"red\")\n",
        "points(outlVals, meanVals,pch = 5, col = \"red\")\n",
        "\n",
        "legend(\"topleft\", legend = c(\"VAR\", \"Mean\"), pch = c(3,5), col = c(\"black\", \"red\"), lty = c(4,2))\n"
      ],
      "metadata": {
        "id": "m2VL_jxsjY0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sample Standard Deviation**\n",
        "\n",
        "The sample standard deviation is the square root of the sample variance,\n",
        "\n",
        "$$\n",
        "\\text{Standard Deviation}(x_1, \\dots, x_n) \\equiv s = \\sqrt{\\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n-1}} = \\sqrt{s^2}.\n",
        "$$"
      ],
      "metadata": {
        "id": "DFc6mCYNlGQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Properties of the Sample Standard Deviation**\n",
        "\n",
        "- Interpreting the sample standard deviation is straightforward because it shares the same units as the original data. For example, if each observation $x_i$ is measured in seconds, then the sample standard deviation $s$ is also expressed in seconds.\n",
        "- The sample standard deviation is sensitive to outliers because it is based on the sample variance, which is not robust. However, the effect of extreme values is somewhat tempered by the square root operation, making the standard deviation less sensitive than the variance, though still not robust to outliers."
      ],
      "metadata": {
        "id": "7U4vOiitmXaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **R Examples**\n",
        "In R, the sample standard deviation can be calculated using the built-in `sd()` function. This function takes a numeric vector as input and returns the sample standard deviation."
      ],
      "metadata": {
        "id": "t5eisvF0oJoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sd(X$G0)\n",
        "sd(X$G0_oult25)\n",
        "sd(X$G0_oult50)\n",
        "sd(X$G0_oult100)"
      ],
      "metadata": {
        "id": "nXHgFZFXo9kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no `colSds()` function in R. However, we can use the `apply()` functions to compute column standard deviations.\n"
      ],
      "metadata": {
        "id": "PHmi1qxHpG_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(apply(X, 2, sd))"
      ],
      "metadata": {
        "id": "dVIIk8FNpL9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This figure demonstrates the smaller rate of increase compared to that of the sample variance."
      ],
      "metadata": {
        "id": "9ZEuMOc7piPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outlVals = c(0,25,50,100)\n",
        "meanVals = apply(X,2,mean)\n",
        "varVals = apply(X,2,var)\n",
        "sdVals = apply(X, 2, sd)\n",
        "\n",
        "\n",
        "plot(outlVals, varVals, type = \"l\", lty = 4, col = \"black\", xaxt = \"n\")\n",
        "points(outlVals, varVals,pch = 3, col = \"black\")\n",
        "axis(side = 1, at = c(0, 25, 50, 100))\n",
        "\n",
        "lines(outlVals, sdVals, type = \"l\", lty = 3, col = \"blue\", xaxt = \"n\")\n",
        "points(outlVals, sdVals,pch = 4, col = \"blue\")\n",
        "\n",
        "lines(outlVals, meanVals, type = \"l\", lty = 2, col = \"red\")\n",
        "points(outlVals, meanVals,pch = 5, col = \"red\")\n",
        "\n",
        "legend(\"topleft\", legend = c(\"VAR\", \"sd\", \"Mean\"), pch = c(3,4,5), col = c(\"black\", \"blue\", \"red\"), lty = c(4,3,2))\n"
      ],
      "metadata": {
        "id": "BB9nuQ5YpOUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **The Empirical Rule For Interpreting Standard Deviation**"
      ],
      "metadata": {
        "id": "WjKgCjdTqzCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the data is not severely deviated from being roughly symmetric, unimodal, and not heavy-tailed, then, in general:\n",
        "\n",
        "- 68% of the observations will fall within one standard deviation of the mean\n",
        "\n",
        "- 95% of the observations will fall within two standard deviations of the mean\n",
        "\n",
        "- 99.7% of the observations will fall within three standard deviations of the mean.\n",
        "\n",
        "These results are connected to the properties of the Gaussian (normal) distribution, which we will study in more detail later. Once you know that the data are  (approximately) generated from a Gaussian distribution, it is safe to use the empirical rule.\n",
        "\n",
        "The Gaussian distribution has the well-known bell-shaped curve. You’ll often hear people say things like “it follows the curve.” That’s because many people claim that the Gaussian distribution shows up everywhere: exam scores, heights, SATs, measurement errors — so many things in the real world tend to follow this curve, **at least approximately**. This distribution is also very \"normal\" in the sense that extreme values are exceedingly rare, making it unlikely to observe outliers far from the mean."
      ],
      "metadata": {
        "id": "PougW5t8r8YL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gaussian Example**"
      ],
      "metadata": {
        "id": "spgdqW0kw7wd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our first example, we generate data from the standard Gaussian (normal) distribution, which satisfies all the conditions under which the empirical rule holds well.\n",
        "\n",
        "We have prepared the `empiricalRuleGaussian()` function, which visualises the empirical rule. The function overlays a histogram of the data with a best-fitting bell-shaped curve and highlights the ±1, ±2,... standard deviation intervals around the mean.\n",
        "\n",
        "It takes a numeric vector as the first argument `data`, the limits of the x-axis as the second argument `xlim`, and the intervals to plot `ks`. By default, the x-axis limits are set to the minimum and maximum of the input vector, and `ks = 1:3` (±1, ±2, and ±3 standard deviation intervals around the mean). We will specify them explicitly in the code for clarity."
      ],
      "metadata": {
        "id": "rU_zP6ibx4rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(59)\n",
        "data = rnorm(2000)\n",
        "empiricalRuleGaussian(data, xlim = c(min(data), max(data)), ks = 1:3)"
      ],
      "metadata": {
        "id": "CCkaJ-TNqIi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on empirical coverage, the empirical rule is generally accurate here."
      ],
      "metadata": {
        "id": "mLZff0sL0c3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Non-Gaussian, Heavy-Tailed Example**"
      ],
      "metadata": {
        "id": "RamJtcsRxV1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the second example, we simulate data from the Student's t-distribution with 2 degrees of freedom. Don’t worry if you’re not familiar with it yet — we’ll explore this distribution in detail later. What’s important now is that the t-distribution with low degrees of freedom is heavy-tailed and symmetric. This means you’re much more likely to see extreme values, both positive and negative, compared to the Gaussian distribution.\n",
        "\n",
        "For instance, in our simulation, we might observe values as extreme as `-40`, which is practically impossible under a standard Gaussian given the age of the universe and all the computing power on Earth."
      ],
      "metadata": {
        "id": "Pxps2ZPoy2gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(59)\n",
        "data = rt(2000,2)\n",
        "empiricalRuleGaussian(data, xlim = c(min(data), max(data)), ks = 1:3)"
      ],
      "metadata": {
        "id": "z7mFZjnAxZy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on empirical coverage, the empirical rule is severely violated here."
      ],
      "metadata": {
        "id": "T4Mw29eQ0TYI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Non-Gaussian, Less Heavy-Tailed Example**"
      ],
      "metadata": {
        "id": "8bQTiQ6t1ZZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the third example, we simulate data from the Student’s t-distribution with 8 degrees of freedom. This t-distribution is symmetric and less heavy-tailed."
      ],
      "metadata": {
        "id": "zqmIY37s18BE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(59)\n",
        "data = rt(2000,8)\n",
        "empiricalRuleGaussian(data, xlim = c(min(data), max(data)), ks = 1:3)"
      ],
      "metadata": {
        "id": "elKmdP_B1_Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on empirical coverage, the empirical rule is acceptable here."
      ],
      "metadata": {
        "id": "8OWBkyUO2Lkp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Non-Gaussian, Skewed Example**"
      ],
      "metadata": {
        "id": "Kw-KZnbAxBW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our forth example, we simulate data from a strongly skewed exponential distribution. This distribution is not symmetric — it has a long tail on one side — meaning extreme values are much more likely on that side, while most observations cluster near zero. It is also non-negative. Don’t worry if this is unfamiliar now — we’ll explore this distribution later in this unit."
      ],
      "metadata": {
        "id": "X5OiNx5m07vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(59)\n",
        "data = rexp(2000, rate = 1)  # Exponential, mode near 0, mean=1\n",
        "empiricalRuleGaussian(data, c(-5, max(data)), ks = 1:3)\n"
      ],
      "metadata": {
        "id": "WDzJ31Uqqk3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on empirical coverage, the empirical rule is severely violated here. Worse, it also covers the negative domain, which is impossible under our data-generating process."
      ],
      "metadata": {
        "id": "VjmQoNCB1Muv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Non-Gaussian, Less Skewed Example**  \n",
        "\n",
        "In the last example, we will apply a log() transformation to the data in the previous example. This transformation tends to make the data more \"normal\" and less skewed — although some skewness may still remain, you should see an improvement in how well the empirical rule holds.\n",
        "\n",
        "**FYI**: The log transformation is a very useful tool in many modelling scenarios as it effectively reduces skewness and stabilises variance. Of course, the raw variables must be non-negative, which may require shifting the values by adding a positive constant (e.g., +1) before applying the transformation (e.g., quite frequently, `income = 0`)."
      ],
      "metadata": {
        "id": "6g8802nd3A8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(59)\n",
        "data = log(rexp(2000, rate = 1))\n",
        "empiricalRuleGaussian(data, c(min(data), 4), ks = 1:3)\n"
      ],
      "metadata": {
        "id": "ItPHFg1x2_9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Still far from the fitted Gaussian curve, but the empirical rule is generally adequate here."
      ],
      "metadata": {
        "id": "6DO2LP2j4PMF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The empirical rule may still apply to data with outliers, but doing so requires using **robust estimators of the standard deviation.**"
      ],
      "metadata": {
        "id": "25qpOJjw5C2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercise**\n",
        "\n",
        "\n",
        "For $k\\geq 1$, given $n$ observations, the Chebyshev’s theorem states that:\n",
        "\n",
        "At least\n",
        "$$1-\\frac{1}{k^2}$$\n",
        "of the observations will lie within $k$ standard deviations of the mean. Or more formally:\n",
        "\n",
        "For a sample of size $n$ and $k\\geq 1$\n",
        "\n",
        "$$\\frac{\\#\\{x|\\bar{x}-ks<x<\\bar{x}+ks\\}}{n}\\geq 1-\\frac{1}{k^2}.$$\n",
        "\n",
        "We have prepared the `chebyshevRule()` function, which is similar to `empiricalRuleGaussian()`, but visualises the Chebyshev's theorem instead. Repeat the same analysis that we did in the previous section and comment on the results.\n"
      ],
      "metadata": {
        "id": "ylk7XpHf5Wzy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gaussian Example**"
      ],
      "metadata": {
        "id": "316vvAjTgx46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(59)\n",
        "data = rnorm(2000)"
      ],
      "metadata": {
        "id": "GdO81vE_7TqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>▶️ Click to show the solution</summary>\n",
        "\n",
        "```r\n",
        "set.seed(59)\n",
        "data = rnorm(2000)\n",
        "chebyshevRule(data, xlim = c(min(data), max(data)), ks = 1:3)\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "IW8NQRE885a7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Non-Gaussian, Heavy-Tailed Example**"
      ],
      "metadata": {
        "id": "9Ej2_j3Qg9Vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(59)\n",
        "data = rt(2000,2)"
      ],
      "metadata": {
        "id": "k1QH0Abt7XZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>▶️ Click to show the solution</summary>\n",
        "\n",
        "```r\n",
        "set.seed(59)\n",
        "data = rt(2000,2)\n",
        "chebyshevRule(data, xlim = c(min(data), max(data)), ks = 1:3)\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "NySSO7iP86GL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Non-Gaussian, Less Heavy-Tailed Example**"
      ],
      "metadata": {
        "id": "aPfCHttSg-nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(59)\n",
        "data = rt(2000,8)"
      ],
      "metadata": {
        "id": "HBFZi_al7X8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>▶️ Click to show the solution</summary>\n",
        "\n",
        "```r\n",
        "set.seed(59)\n",
        "data = rt(2000,8)\n",
        "chebyshevRule(data, xlim = c(min(data), max(data)), ks = 1:3)\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "Z-goM_0u8-he"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Non-Gaussian, Skewed Example**"
      ],
      "metadata": {
        "id": "SIJX7jUVhEuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(59)\n",
        "data = rexp(2000, rate = 1)"
      ],
      "metadata": {
        "id": "mvOrUL3b7YMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>▶️ Click to show the solution</summary>\n",
        "\n",
        "```r\n",
        "set.seed(59)\n",
        "data = exp(2000, 1)\n",
        "chebyshevRule(data, xlim = c(-5, max(data), ks = 1:3))\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "4GDOFp--9BIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Non-Gaussian, Less Skewed Example**  "
      ],
      "metadata": {
        "id": "NFLsR6__hKQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(59)\n",
        "data = log(rexp(2000, rate = 1))"
      ],
      "metadata": {
        "id": "OfpkbuMX7YZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>▶️ Click to show the solution</summary>\n",
        "\n",
        "```r\n",
        "set.seed(59)\n",
        "data = log(rexp(2000, rate = 1))\n",
        "chebyshevRule(data, xlim = c(min(data), 4), ks = 1:3)\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "s2OOYdF88wi_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>▶️ Click to show comments on the results</summary>\n",
        "\n",
        "Unlike the empirical rule, the Chebyshev's theorem **ALWAYS** holds. However, it only gives a lower-bound and is very conservative (e.g., when $k = 1$, it says at least $0\\%$ of the data will be between ±1 SD). It is less powerful than the empirical rule.\n",
        "</details>"
      ],
      "metadata": {
        "id": "xPtS2Bwb9a07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Range-based Estimate of Standard Deviation**"
      ],
      "metadata": {
        "id": "_D5lQUHf-gUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes, you may not have access to the raw values of individual observations — for example, due to privacy concerns — but you still want to estimate the standard deviation of the dataset.\n",
        "\n",
        "A **rule of thumb** based on a **backward application of the empirical rule** provides a rough approximation of the standard deviation.\n",
        "\n",
        "The empirical rule tells us that:\n",
        "\n",
        "- Approximately **95% of the data** in a bell-shaped (Gaussian-like) distribution falls within **±2 standard deviations** of the mean.\n",
        "\n",
        "So, if we assume that **most of the dataset is contained within ±2 SD**, we can approximate the standard deviation $s$ by:\n",
        "\n",
        "$$\n",
        "\\tilde{s} = \\frac{\\text{range}}{4}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- **range** = maximum − minimum value of the dataset.\n",
        "\n",
        "This is a **crude but often surprisingly effective estimate**, especially when the data are roughly symmetric and not heavily skewed or multimodal.  \n",
        "However, it becomes a **poor estimate when these assumptions are violated**, as the empirical rule no longer holds well in such cases.\n"
      ],
      "metadata": {
        "id": "8wk4rV56_Qlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **R Examples**\n",
        "\n",
        "To compute the range-based estimate of standard deviation of `x`, we can simply take `max(x) - min(x)`. We have implemented this estimator in the 'rangeBasedSD()' function, which takes a numeric vector and outputs the range-based estimate of sample standard deviation.\n",
        "\n",
        "Back to our `X` data frame containing four datasets with increasing magnitude of outlying values."
      ],
      "metadata": {
        "id": "dhCOM7oLB9ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(apply(X, 2, rangeBasedSD))\n",
        "print(apply(X, 2, sd))"
      ],
      "metadata": {
        "id": "7gAsLRkXCiVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the range-based estimate deteriorates as the magnitude of outliers increases. However, the scatter plot still remains relatively close to the ideal $y = x$ line. Is this method useful? Yes and No:\n",
        "- Yes, because it gives a good estimate of the correct sample standard deviation,\n",
        "- No, because the estimate is still heavily influenced by outliers. A robust estimate should give us a value close to 1 **as the non-outlying observations have a standard deviation of 1 theoretically**.\n"
      ],
      "metadata": {
        "id": "G7B5ZOpJDSvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot(apply(X, 2, rangeBasedSD), apply(X, 2, sd),\n",
        "     xlab = \"rangeBasedSD\", ylab = \"SD\", main = \"rangeBasedSD vs. SD\",\n",
        "     xlim = c(0,30), ylim = c(0,30))\n",
        "abline(a = 0, b= 1, col = \"red\")"
      ],
      "metadata": {
        "id": "rXAek1JqC4eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Quantiles and the Interquartile Range (IQR)**\n",
        "\n",
        "\n",
        "For a set of $n$ observations $x_1,x_2,\\dots,x_n$, $x_q$ is the q$th$ quantile if q$\\%$ of the observations are less than $x_q$. Common quantiles include:\n",
        "\n",
        "- **The median** — the value below which 50% of the data fall.\n",
        "- **Quartiles**: Divide data into four equal parts.\n",
        "  - **Q1 (25th percentile)**: The value below which 25% of the data fall.\n",
        "  - **Q2 (50th percentile)**: The median.\n",
        "  - **Q3 (75th percentile)**: The value below which 75% of the data fall.\n",
        "\n",
        "#### **The Inter-Quartile Range (IQR)**\n",
        "\n",
        "The interquartile range (IQR) is the distance between the 25$th$ and the 75$th$ quantiles, or the range covering the “middle” 50% of the data. The IQR is sometimes used as a robust measure of dispersion because it isn’t affected by extreme values, unlike the range or the variance.\n",
        "\n",
        "$$\n",
        "\\text{IQR} = Q_3 - Q_1\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "0gHu1CmUEmui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **R Examples**\n",
        "\n",
        "To compute quantiles of a numeric vector in **R**, we can use the `quantile()` function, which requires the input vector and the desired quantile level(s). For example, `quantile(x, probs = 0.75)` returns the 75th percentile of the vector `x`.\n"
      ],
      "metadata": {
        "id": "9Yc4uFPtLUOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantile(X$G0, 0.5)\n",
        "median(X$G0)"
      ],
      "metadata": {
        "id": "299OdzpTL9w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to compute the $75\\%$ quantiles of all columns in the data frame `X` using `apply()`, things become a bit more complicated now.\n",
        "\n",
        "The function `apply(X, MARGIN, FUN)` expects a function object as its third argument. This is why passing function names like `mean`, `median`, or `sd` directly works — because those are already defined as functions in R.\n",
        "However, if you try something like `quantile(probs = 0.75)`, R throws an error. That’s because `quantile(probs = 0.75)` is **NOT** a function — it’s trying to immediately evaluate quantile() without being given any data input.\n",
        "\n",
        "To fix this, you need to explicitly define an anonymous function that takes one argument, and passes it to `quantile()` along with your desired parameter. For example:"
      ],
      "metadata": {
        "id": "2QFgrI6XMDkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class(mean)\n",
        "class(function(arg) quantile(arg, probs = 0.75))\n",
        "\n",
        "print(apply(X,2,function(arg) quantile(arg, probs = 0.75)))"
      ],
      "metadata": {
        "id": "bAaGv0L4NfrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercise**\n",
        "\n",
        "Assign the vectorised evaluation of the 75$th$ percentiles of the columns in `X` (using `apply()`, as shown above) to a variable named `q75`. This will produce a numeric vector.\n",
        "\n",
        "Repeat the same process to calculate the 25$th$ percentiles of the columns in `X`, and assign the result to a variable named `q25`.\n",
        "\n",
        "Then, using a simple vector operation to compute the interquartile ranges (IQRs) for all columns in `X`.\n"
      ],
      "metadata": {
        "id": "LyHyn7AHOU0o"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JGjgaAR8PSWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>▶️ Click to show the solution</summary>\n",
        "\n",
        "```r\n",
        "q75 = apply(X,2,function(arg) quantile(arg, probs = 0.75))\n",
        "q25 = apply(X,2,function(arg) quantile(arg, probs = 0.25))\n",
        "iqr = q75 - q25\n",
        "print(iqr)\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "YgDDc-NvPc1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **IQR-Based Estimate of Standard Deviation**\n",
        "\n",
        "For data that is approximately normally distributed, the standard deviation $\\sigma$ can be estimated from the IQR using the relation:\n",
        "\n",
        "$$\n",
        "\\hat{s} \\approx \\frac{\\text{IQR}}{1.349}\n",
        "$$\n",
        "\n",
        "This is because, in a normal distribution, the IQR covers approximately 1.349 standard deviations.\n",
        "\n",
        "We have implemented this estimator in the `IQRBasedSD()` function, which takes a numeric vector and returns an IQR-based estimate of sample standard deviation."
      ],
      "metadata": {
        "id": "xgf8N6WGLP70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(apply(X, 2, IQRBasedSD))\n",
        "print(apply(X, 2, sd))"
      ],
      "metadata": {
        "id": "tDrWMx6AJ9t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The IQR-based estimates are close to 1 (the blue dashed line), so this method is more robust to outliers than `rangeBasedSD()` and `sd()`. Like the median, this method is generally not affected by the magnitude of outliers. At least, in our example, only at most $10\\%$ of each dataset are outliers, so IQR is quite a robust variability measure."
      ],
      "metadata": {
        "id": "sCLwNqQsKLC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot(apply(X, 2, IQRBasedSD), apply(X, 2, sd),\n",
        "     xlab = \"IQRBasedSD\", ylab = \"SD\", main = \"IQRBasedSD vs. SD\",\n",
        "     xlim = c(0,30), ylim = c(0,30))\n",
        "abline(a = 0, b= 1, col = \"red\")\n",
        "abline(v = 1, lty = 2, col = \"blue\")"
      ],
      "metadata": {
        "id": "-A-zI_zoJnMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Measure of Shape**\n",
        "\n",
        "While measures of central tendency (like the mean and median) and variability (like the variance and standard deviation) describe the location and spread of a distribution, **measures of shape** provide insight into the distribution's symmetry and tail behavior.\n",
        "\n",
        "In this section, however, we will focus only on the measure of symmetry.\n",
        "\n",
        "### **Sample Skewness**\n",
        "\n",
        "Skewness quantifies the **asymmetry** of the distribution. The sample skewness is defined as:\n",
        "\n",
        "$$\n",
        "\\text{Skewness}(x_1,x_2,...,x_n) = \\frac{n}{(n-1)(n-2)} \\sum_{i=1}^n \\left( \\frac{x_i - \\bar{x}}{s} \\right)^3\n",
        "$$\n",
        "\n",
        "- A skewness near $0$ indicates that the data are approximately symmetric.\n",
        "- A **positive skew** (right-skewed) indicates a longer or fatter tail on the right.\n",
        "- A **negative skew** (left-skewed) indicates a longer or fatter tail on the left.\n",
        "\n",
        "Skewness is useful for detecting departures from symmetry that may affect modeling assumptions, especially for techniques assuming normality.\n",
        "\n",
        "#### **R Examples**\n"
      ],
      "metadata": {
        "id": "jSreOlJsP4yJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first import `skewed.csv`, which contains several datasets exhibiting increasing levels of skewness."
      ],
      "metadata": {
        "id": "ELY1062wSDMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skewed = read.csv(\"datasets/skewed.csv\")\n",
        "par(mfrow = c(2,4))\n",
        "for(i in 1:7){hist(skewed[,i], xlab = \"\", main = colnames(skewed)[i], breaks = 25)}\n",
        "par(mfrow = c(1,1))"
      ],
      "metadata": {
        "id": "LI6KB5wyQ2km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no `skewness()` function in base R. However, we have prepared `skewness()` function, which takes a numeric vector and return the sample skewness."
      ],
      "metadata": {
        "id": "qjoidm2KSX9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(apply(skewed,2,skewness))"
      ],
      "metadata": {
        "id": "G2zdpz1NRWTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In practice, positive skewness is more commonly observed than negative skewness. For example, the previously seen weekly earnings data exhibit positive skewness."
      ],
      "metadata": {
        "id": "RMzPyNaOSiK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img = readPNG(\"figures/abs_earning.png\")\n",
        "grid.newpage()\n",
        "vp = viewport(width = 1.25, height = 1.25)\n",
        "pushViewport(vp)\n",
        "grid.raster(img)\n",
        "popViewport()"
      ],
      "metadata": {
        "id": "6R5_qKV2Thnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercise**\n",
        "\n",
        "Provide a real-world example that exhibits negative skewness.\n"
      ],
      "metadata": {
        "id": "Bf0zpnqQTu9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>▶️ Click to show the solution</summary>\n",
        "\n",
        "It would be quite concerning if the age at death were positively skewed—that is, if most people died young and only a few lived to an old age.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "2iIL7pKlT4GG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sample Kurtosis (Not Covered In This Unit)**\n",
        "\n",
        "<details>\n",
        "<summary> Click to show the content </summary>\n",
        "\n",
        "Kurtosis measures the **tailedness** of the distribution — how prone it is to producing extreme values. The sample kurtosis is given by:\n",
        "\n",
        "$$\n",
        "\\text{Kurtosis}(x_1,x_2,...,x_n) =  \\frac{n(n+1)}{(n-1)(n-2)(n-3)} \\sum_{i=1}^n \\left( \\frac{x_i - \\bar{x}}{s} \\right)^4 - \\frac{3(n-1)^2}{(n-2)(n-3)} + 3\n",
        "$$\n",
        "\n",
        "- For normally distributed data, this value is approximately $3$.\n",
        "- **Excess kurtosis** is defined as:\n",
        "\n",
        "$$\n",
        "\\text{Excess Kurtosis} = \\text{Kurtosis} - 3\n",
        "$$\n",
        "\n",
        "- A positive excess kurtosis ( > 0 ) indicates **heavy tails** (more prone to extreme values).\n",
        "- A negative excess kurtosis ( < 0 ) indicates **light tails** (fewer extreme values).\n",
        "- For normally distributed data, this value is approximately $0$.\n",
        "\n",
        "Kurtosis helps diagnose whether standard deviation is a reliable measure of spread or whether extreme values dominate the variability.\n",
        "\n",
        "#### **R Examples**\n",
        "We first import `kurtotic.csv`, which contains three datasets exhibiting different levels or \"tailedness\".\n",
        "\n",
        "There is no `kurtosis()` function in base R. However, we have prepared `kurtosis()` function, which takes a numeric vector and return the sample excess kurtosis.\n",
        "\n",
        "```r\n",
        "\n",
        "kurtotic = read.csv(\"datasets/kurtotic.csv\")\n",
        "\n",
        "#Histograms of the datasets\n",
        "par(mfrow = c(2,2))\n",
        "for(i in 1:4){hist(kurtotic[,i], xlab = \"\", main = colnames(kurtotic)[i], breaks = 25)}\n",
        "par(mfrow = c(1,1))\n",
        "#Computes kurtosis\n",
        "print(apply(kurtotic,2,kurtosis))\n",
        "\n",
        "```\n",
        "\n",
        "```r\n",
        "```\n",
        "\n",
        "#### **Exercise**\n",
        "\n",
        "The following code cell loads the `s&p500.csv` dataset for daily returns of `S&P 500` index from `03/01/2000` to `18/07/2025`, queried from Yahoo Finance, then plots the histogram of daily returns of `S&P 500` and calculates the excess kurtosis.\n",
        "\n",
        "Comment on the results.\n",
        "\n",
        "```r\n",
        "sp500_dailyReturn = 100*read.csv(\"datasets/s&p500.csv\")$daily.returns\n",
        "hist(sp500_dailyReturn, main = \"Histogram of daily returns of S&P500 (03/01/2000 - 18/07/2025)\", xlab = \"Return\", freq = T)\n",
        "kurtosis(sp500_dailyReturn)\n",
        "```\n",
        "\n",
        "Daily return data are heavy-tailed, not normally distributed. Modelling daily returns as being normally distributed will severely underestimate the risk.\n",
        "\n",
        "**FYI**: In the 2008 financial crisis, many quantitative models failed to predict the magnitude of losses during the crisis because they **assumed normality**, ignoring the **true fat-tailed nature** of financial returns.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "R5fhk9dWQuYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Boxplot**"
      ],
      "metadata": {
        "id": "rIUTnzR-a0ax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **What Does a Boxplot Tell Us?**"
      ],
      "metadata": {
        "id": "tKvpcsMfcwvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used boxplots in previous examples, but we have not described what exactly a boxplot tells you.\n",
        "\n",
        "A boxplot displays:\n",
        "- The **median** (central line),\n",
        "- The **interquartile range (IQR)** between Q1 and Q3 (the box),\n",
        "- The **whiskers**, which extend to the most extreme data points within 1.5$\\times$IQR from the quartiles,\n",
        "- And **outliers**, plotted as points beyond the whiskers.\n",
        "\n",
        "We have prepared the `boxplotDescribe()` function to visualise this."
      ],
      "metadata": {
        "id": "nMhPQNGUbMy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boxPlotDescribe()"
      ],
      "metadata": {
        "id": "p6WLiwubbjKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have demonstrated how to create boxplots in base R using the boxplot() function.\n",
        "- If you input a numeric vector, it creates a single boxplot.\n",
        "- If you input a data frame or matrix, it creates boxplots for each column, allowing you to compare their distributions side by side."
      ],
      "metadata": {
        "id": "273lF0C2cYNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boxplot(X)"
      ],
      "metadata": {
        "id": "B6DFtDfzcsWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Create A Boxplot in `ggplot2`**"
      ],
      "metadata": {
        "id": "IVtWZCe2cuKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **A Single Boxplot**\n"
      ],
      "metadata": {
        "id": "HZrdIrQcfbX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crreating a single boxplot for a numeric vector using `ggplot2` is simple. You only need to convert the numeric vector to a data frame before passing it into the `ggplot()` function."
      ],
      "metadata": {
        "id": "WOnTnQVUffb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(59)\n",
        "numVec = rnorm(2000)\n",
        "data = data.frame(Value = numVec)\n",
        "\n",
        "data %>% ggplot(aes(y = Value)) +  # empty x to get a single boxplot\n",
        "  geom_boxplot() +\n",
        "  labs(title = \"Boxplot of a Single Numeric Vector\", x = \"\", y = \"Value\") +\n",
        "  theme_minimal()"
      ],
      "metadata": {
        "id": "Cd3fOUhefnSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Multiple Boxplots**"
      ],
      "metadata": {
        "id": "2jlVBqZ7drCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating multiple boxplots with **ggplot2** is relatively more involved than with base R. One key difference is how **ggplot2** handles data:\n",
        "\n",
        "In `ggplot2`, the **y-axis** represents the values of a single variable. If your data frame has **multiple columns** (e.g., multiple numeric variables), you **cannot** directly plot them all in one call using:\n",
        "\n",
        "```r\n",
        "ggplot(data, aes(y = c(\"col1\", \"col2\")))\n",
        "```\n",
        "\n",
        "This simply does not work. The solution is to use long-format data."
      ],
      "metadata": {
        "id": "8ITGiPVec7z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X %>%\n",
        "  pivot_longer(cols = everything(),\n",
        "               names_to = \"Dataset\",\n",
        "               values_to = \"Value\") %>%\n",
        "  mutate(Dataset = factor(Dataset, levels = colnames(X))) -> longX #This is to preserved the column orders in the original dataframe `X`\n",
        "  #instead of sorting alphabetically.\n",
        "\n",
        "longX %>% ggplot(aes(x = Dataset, y = Value, color = Dataset)) +\n",
        "                 geom_boxplot() +\n",
        "                 labs(\n",
        "                      title = \"Boxplots of datasets with varying magnitudes of outliers\",\n",
        "                      x = \"Column\", y = \"Value\", color = \"Column\"\n",
        "                      ) +\n",
        "                 theme_minimal() +\n",
        "                 theme(\n",
        "                       plot.title = element_text(face = \"bold\", size = 14, hjust = 0.5),\n",
        "                       legend.position = \"top\"\n",
        "                 )\n",
        "\n"
      ],
      "metadata": {
        "id": "xhOvsXUsd23z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercise**\n",
        "\n",
        "Add **ONE** line of code to the following code cell to create boxplots of columns in `skewed` data.frame."
      ],
      "metadata": {
        "id": "u4StJvMygqJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X %>%\n",
        "  pivot_longer(cols = everything(),\n",
        "               names_to = \"Dataset\",\n",
        "               values_to = \"Value\") %>%\n",
        "  mutate(Dataset = factor(Dataset, levels = colnames(X))) -> longX\n",
        "\n",
        "longX %>% ggplot(aes(x = Dataset, y = Value, color = Dataset)) +\n",
        "                 geom_boxplot() +\n",
        "                 labs(\n",
        "                      title = \"Boxplots of datasets with varying skewness levels\",\n",
        "                      x = \"Column\", y = \"Value\", color = \"Column\"\n",
        "                      ) +\n",
        "                 theme_minimal() +\n",
        "                 theme(\n",
        "                       plot.title = element_text(face = \"bold\", size = 14, hjust = 0.5),\n",
        "                       legend.position = \"top\"\n",
        "                 )"
      ],
      "metadata": {
        "id": "M71P6ue-gVgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>▶️ Click to show the solution</summary>\n",
        "\n",
        "```r\n",
        "X = skewed\n",
        "X %>%\n",
        "  pivot_longer(cols = everything(),\n",
        "               names_to = \"Dataset\",\n",
        "               values_to = \"Value\") %>%\n",
        "  mutate(Dataset = factor(Dataset, levels = colnames(X))) -> longX\n",
        "  \n",
        "longX %>% ggplot(aes(x = Dataset, y = Value, color = Dataset)) +\n",
        "                 geom_boxplot() +\n",
        "                 labs(\n",
        "                      title = \"Boxplots of datasets with varying skewness levels\",\n",
        "                      x = \"Column\", y = \"Value\", color = \"Column\"\n",
        "                      ) +\n",
        "                 theme_minimal() +\n",
        "                 theme(\n",
        "                       plot.title = element_text(face = \"bold\", size = 14, hjust = 0.5),\n",
        "                       legend.position = \"top\"\n",
        "                 )\n",
        "```\n",
        "  \n",
        "</details>"
      ],
      "metadata": {
        "id": "Zo-ne_1bgl2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Workshop Questions**"
      ],
      "metadata": {
        "id": "QtPUbL3-nRXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 1**\n",
        "\n",
        "The empirical rule can be extended beyond ±3 standard deviations.\n",
        "\n",
        "| Interval | Approx. % of Data |\n",
        "| -------- | ----------------- |\n",
        "| ±1 SD    | 68.27%            |\n",
        "| ±2 SD    | 95.45%            |\n",
        "| ±3 SD    | 99.73%            |\n",
        "| ±4 SD    | 99.994%           |\n",
        "| ±5 SD    | 99.99994%         |\n",
        "| ±6 SD    | 99.9999998%       |\n",
        "\n",
        "\n",
        "\n",
        "The following code cell loads daily returns of `S&P 500` index from `03/01/2000` to `18/07/2025` from `s&p500.csv`, queried from Yahoo Finance. Use the `empiricalRuleGaussian()` function to visualise the empirical rule for up to ±6 standard deviations. Compare the empirical and theoretical coverage."
      ],
      "metadata": {
        "id": "PtnuqYSpnYYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sp500_dailyReturn = 100*read.csv(\"datasets/s&p500.csv\")$daily.returns"
      ],
      "metadata": {
        "id": "h9CxhfpXnj2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>▶️ Click to show the solution</summary>\n",
        "\n",
        "Solution will be released at the end of the week!\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "GMod1L0VniiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **EPA Fuel Economy Dataset**\n",
        "\n",
        "A dataset containing information on over 13,500 cars sold in the US from 2010 to 2020, including measurements and characteristics related to vehicle fuel economy and specifications. Data sourced from the [US Fuel Economy website](https://www.fueleconomy.gov/feg/download.shtml).\n",
        "\n",
        "| Variable | Description                                    |\n",
        "|----------|------------------------------------------------|\n",
        "| `city`   | EPA measured fuel economy in miles per gallon (city driving) |\n",
        "| `hwy`    | EPA measured fuel economy in miles per gallon (highway driving) |\n",
        "| `cyl`    | Number of cylinders in the engine              |\n",
        "| `disp`   | Engine displacement (litres)                    |\n",
        "| `drive`  | Vehicle drivetrain layout (e.g., FWD, RWD, AWD) |\n",
        "| `make`   | Vehicle manufacturer name                       |\n",
        "| `model`  | Vehicle model name                              |\n",
        "| `trans`  | Transmission type (manual or automatic)        |\n",
        "| `year`   | Vehicle model year                              |\n"
      ],
      "metadata": {
        "id": "ahPgOogUoFCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epa_data = read.csv(\"./datasets/epa_data.csv\")\n",
        "str(epa_data)"
      ],
      "metadata": {
        "id": "8Yf-TVzCnwJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 2**\n",
        "\n",
        "What is the mean and median city fuel economy for cars in the epa_data set? What is the mean, median, and mode for engine displacement?\n",
        "\n",
        "**Hint**: Use the provided `Mode()` function. Use `na.rm = TRUE` option in `mean` and `median` to avoid errors caused by missing values. You may use the `summarise()` function for better readability."
      ],
      "metadata": {
        "id": "x4km73sonktE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TiZvXUN8n2NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<details>\n",
        "<summary>▶️ Click to show the solution</summary>\n",
        "\n",
        "Solution will be released at the end of the week!\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "y7Z_cmY6nuts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 3**\n",
        "\n",
        "Compute the variances and standard deviations for EPA city and highway mileage. Use Chebyshev’s theorem and the empirical rule to interpret the results. Is the empirical rule adequate?\n",
        "\n",
        "**Hint**: Use the provided `empiricalRuleGaussian()` and `chebyshevRule()` functions. Use `na.rm = T` if needed."
      ],
      "metadata": {
        "id": "JZhNXLP6oeM_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JKahaTznovZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<details>\n",
        "<summary>▶️ Click to show the solution</summary>\n",
        "\n",
        "Solution will be released at the end of the week!\n",
        "</details>"
      ],
      "metadata": {
        "id": "PB83VdrPou2g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 4**\n",
        "\n",
        "Compute the three quartiles and interquartile ranges for EPA city and highway mileage. Then, create side-by-side boxplots to visually compare city and highway mileage.\n",
        "\n",
        "**Hint**: We may need a long format data frame to side-by-side boxplots.\n"
      ],
      "metadata": {
        "id": "xWK4gn1fo1aJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7zPnoW3OphiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<details>\n",
        "<summary>▶️ Click to show the solution</summary>\n",
        "\n",
        "Solution will be released at the end of the week!\n",
        "</details>"
      ],
      "metadata": {
        "id": "pjzrvNBqpjDy"
      }
    }
  ]
}